{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads Data from Stock-net Dataset\n",
    "\n",
    "Dataset can be found [here](https://github.com/yumoxu/stocknet-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this filepath to your relative path\n",
    "stocknet_dataset_filepath = './stocknet-dataset-master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data into maps\n",
    "`company_to_price_df` maps each company name to a DataFrame containing the stock movement information per date. Schema:\n",
    "```\n",
    "{\n",
    "    company_name: DataFrame ['date', 'open', 'high', 'low', 'close', 'adjust_close', 'volume']\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "`company_to_tweets` maps each company name to a dictionary of dates and list of tweets. Schema:\n",
    "```\n",
    "{\n",
    "    company_name: \n",
    "    {\n",
    "        date: [list of tweets + metadata]\n",
    "        ...\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "NOTE: GMRE is not included because it does not include dates before 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:05<00:00, 15.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data import\n",
    "preprocessed_prices_filepath = stocknet_dataset_filepath + '/price/preprocessed'\n",
    "preprocessed_tweets_filepath = stocknet_dataset_filepath + '/tweet/preprocessed'\n",
    "\n",
    "company_to_price_df = {}\n",
    "company_to_tweets = {}\n",
    "\n",
    "for filename in os.listdir(preprocessed_prices_filepath):\n",
    "    with open(preprocessed_prices_filepath + '/' + filename) as file:\n",
    "        company_name = filename.split('.')[0]\n",
    "        \n",
    "        # Not enough data for GMRE\n",
    "        if company_name == 'GMRE':\n",
    "            continue\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        df.columns = ['date', 'open', 'high', 'low', 'close', 'adjust_close', 'volume']\n",
    "        company_to_price_df[company_name] = df\n",
    "\n",
    "for filename in tqdm(os.listdir(preprocessed_tweets_filepath)):\n",
    "    company_name = filename.split('.')[0]\n",
    "    dates_to_tweets = {}\n",
    "    for tweet_filename in os.listdir(preprocessed_tweets_filepath + '/' + filename):\n",
    "        with open(preprocessed_tweets_filepath + '/' + filename + '/' + tweet_filename) as file:\n",
    "            list_of_tweets = []\n",
    "            for line in file:\n",
    "                tweet_json = json.loads(line)\n",
    "                list_of_tweets.append(tweet_json)\n",
    "            dates_to_tweets[tweet_filename] = list_of_tweets\n",
    "    company_to_tweets[company_name] = dates_to_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Dev / Test Split for Price\n",
    "The dates are as specified for the train / dev / test split:\n",
    "* 01/01/2014 to 31/07/2015 for training\n",
    "* 01/08/2015 to 30/09/2015 for validation\n",
    "* 01/10/2015 to 01/01/2016 for testing\n",
    "\n",
    "There are 6 companies that don't have 1256 rows in their stock data, 3 of which have 1255 rows (PTR, REX, SNP). The remaining 3 each have varying numbers of rows (BABA, AFGS, ABBV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / dev / test split\n",
    "COMPANIES_1255 = ['PTR', 'REX', 'SNP']\n",
    "DIFF_COMPANIES = ['BABA', 'AGFS', 'ABBV']\n",
    "\n",
    "TRAIN_IDXS = range(526, 924)\n",
    "TRAIN_IDXS_1255 = range(525, 923)\n",
    "TRAIN_IDXS_BABA = range(526, 743)\n",
    "TRAIN_IDXS_AGFS = range(526, 699)\n",
    "TRAIN_IDXS_ABBV = range(526, 924)\n",
    "\n",
    "DEV_IDXS = range(484, 526)\n",
    "TEST_IDXS = range(419, 484)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build price tensors per company\n",
    "\n",
    "`company_to_price_tensors_{dataset}` maps each company name to a numpy tensor of dimension `len({dataset}) x 3`. Each feature vector is structured as `[closing_price, high_price, low_price]`. Schema:\n",
    "\n",
    "```\n",
    "{\n",
    "    company_name: \n",
    "        numpy.array([\n",
    "            [closing_price, high_price, low_price],\n",
    "            ...\n",
    "        ])\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build price tensor per company [closing, highest, lowest] & split data up\n",
    "company_to_price_tensors_train = {}\n",
    "company_to_price_tensors_dev = {}\n",
    "company_to_price_tensors_test = {}\n",
    "\n",
    "# Helper method for building tensor\n",
    "def build_price_tensor(company, idxs):\n",
    "    tensor = []\n",
    "    for index, row in company_to_price_df[company].iloc[idxs].iterrows():\n",
    "        tensor.append([row['close'], row['high'], row['low']])\n",
    "    return np.array(tensor)\n",
    "\n",
    "# Build training tensors for prices\n",
    "for company in company_to_price_df.keys():\n",
    "    # Skip over companies that dont match for now\n",
    "    if company in COMPANIES_1255 or company in DIFF_COMPANIES:\n",
    "        continue\n",
    "    company_to_price_tensors_train[company] = build_price_tensor(company, TRAIN_IDXS)\n",
    "\n",
    "# Build training tensors for prices\n",
    "for company in company_to_price_df.keys():\n",
    "    # Skip over companies that dont match for now\n",
    "    if company in COMPANIES_1255 or company in DIFF_COMPANIES:\n",
    "        continue\n",
    "    company_to_price_tensors_dev[company] = build_price_tensor(company, DEV_IDXS)\n",
    "\n",
    "# Build training tensors for prices\n",
    "for company in company_to_price_df.keys():\n",
    "    # Skip over companies that dont match for now\n",
    "    if company in COMPANIES_1255 or company in DIFF_COMPANIES:\n",
    "        continue\n",
    "    company_to_price_tensors_test[company] = build_price_tensor(company, TEST_IDXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_nlp",
   "language": "python",
   "name": "py38_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
