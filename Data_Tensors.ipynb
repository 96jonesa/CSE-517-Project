{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lVjNK8shFKOC"
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet \"tensorflow-hub>=0.7.0\"\n",
    "!pip3 install --quiet seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MSeY-MUQo2Ha"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kxiao36/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocknet_dataset_filepath = './stocknet-dataset-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-13857e9da74f>:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for filename in tqdm_notebook(os.listdir(preprocessed_tweets_filepath)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eb6816c52343ac8a84717126bc9723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_prices_filepath = stocknet_dataset_filepath + '/price/preprocessed'\n",
    "preprocessed_tweets_filepath = stocknet_dataset_filepath + '/tweet/preprocessed'\n",
    "\n",
    "company_to_price_df = {}\n",
    "company_to_tweets = {}\n",
    "\n",
    "for filename in os.listdir(preprocessed_prices_filepath):\n",
    "    with open(preprocessed_prices_filepath + '/' + filename) as file:\n",
    "        company_name = filename.split('.')[0]\n",
    "        \n",
    "        # Not enough data for GMRE\n",
    "        if company_name == 'GMRE':\n",
    "            continue\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        df.columns = ['date', 'open', 'high', 'low', 'close', 'adjust_close', 'volume']\n",
    "        company_to_price_df[company_name] = df.dropna()\n",
    "\n",
    "for filename in tqdm_notebook(os.listdir(preprocessed_tweets_filepath)):\n",
    "    company_name = filename.split('.')[0]\n",
    "    dates_to_tweets = {}\n",
    "    for tweet_filename in os.listdir(preprocessed_tweets_filepath + '/' + filename):\n",
    "        with open(preprocessed_tweets_filepath + '/' + filename + '/' + tweet_filename) as file:\n",
    "            list_of_tweets = []\n",
    "            for line in file:\n",
    "                tweet_json = json.loads(line)\n",
    "                list_of_tweets.append(tweet_json)\n",
    "            dates_to_tweets[tweet_filename] = list_of_tweets\n",
    "    company_to_tweets[company_name] = dates_to_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['rt', '$', 'tsla', 'hft', 'algos', 'triggered', 'buy', 'in', 'sigma-x', ',', 'crossfinder', ',', 'ats', ',', 'lx', '@', '08:28', ',', 'p', '/', 't', '245.00', 'quant', '$', 'msft', '$', 'fb', '$', 'gpro', '$', 'amzn', '$', 'goog', '$', 'aapl', '$', 'nflx', '$', 'qqq'], 'created_at': 'Fri Oct 02 12:29:15 +0000 2015', 'user_id_str': '242469235'}\n"
     ]
    }
   ],
   "source": [
    "#print(company_to_tweets.keys())\n",
    "#print(dates_to_tweets.keys())\n",
    "print(company_to_tweets['AAPL']['2015-10-02'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "def embed_useT(module):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})\n",
    "embed_fn = embed_useT(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-418da3d99a41>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for company in tqdm_notebook(company_to_tweets.keys()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5788c0407b35469383f36cc308399a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "for company in tqdm_notebook(company_to_tweets.keys()):\n",
    "  for date in company_to_tweets[company].keys():\n",
    "    messages = []\n",
    "    for j in range(len(company_to_tweets[company][date])):\n",
    "      messages.append(' '.join(company_to_tweets[company][date][j]['text']))\n",
    "    message_embeddings = embed_fn(messages)\n",
    "    for k in range(len(company_to_tweets[company][date])):\n",
    "      company_to_tweets[company][date][k]['embedding'] = list(message_embeddings[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date mapping\n",
    "date_universe = set()\n",
    "for company in company_to_price_df.keys():\n",
    "    date_universe = date_universe.union(set(company_to_price_df[company].date))\n",
    "for company in company_to_tweets.keys():\n",
    "    date_universe = date_universe.union(set(company_to_tweets[company].keys()))\n",
    "date_universe = sorted(list(date_universe))\n",
    "index_to_date = {i-5:d for i,d in enumerate(date_universe)}\n",
    "date_to_index = {d:i-5 for i,d in enumerate(date_universe)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "1473\n",
      "555\n"
     ]
    }
   ],
   "source": [
    "# Calculate dimensions for tensor\n",
    "n_stocks = len(company_to_tweets.keys())\n",
    "n_days = len(date_universe)\n",
    "max_tweets = 0\n",
    "for c,d in itertools.product(company_to_tweets.keys(), date_universe):\n",
    "    if d in company_to_tweets[c]:\n",
    "        max_tweets = max(max_tweets, len(company_to_tweets[c][d]))\n",
    "# Create index mapping for stocks alphabetically\n",
    "company_to_index = {c:i for i,c in enumerate(sorted(list(company_to_tweets.keys())))}\n",
    "# print dimensions\n",
    "print(n_stocks)\n",
    "print(n_days)\n",
    "print(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct tensors\n",
    "price_tensor = np.zeros((n_stocks, n_days-5, 6, 3))\n",
    "smi_tensor = np.zeros((n_stocks, n_days-5, 6, max_tweets, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-76de29a2aab5>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for company in tqdm_notebook(company_to_price_df.keys()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b4ef5ca35e4149a3cd17195e39b49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SMI tensor\n",
    "for company in tqdm_notebook(company_to_price_df.keys()):\n",
    "    dates = sorted(list(company_to_price_df[company].date))\n",
    "    lags = []\n",
    "    for date in dates[:5]:\n",
    "        entry = []\n",
    "        row = company_to_price_df[company].loc[company_to_price_df[company]['date'] == date]\n",
    "        entry.append(row['high'].values[0])\n",
    "        entry.append(row['low'].values[0])\n",
    "        entry.append(row['adjust_close'].values[0])\n",
    "        lags.append(entry)\n",
    "    for date in dates[5:]:\n",
    "        entry = []\n",
    "        row = company_to_price_df[company].loc[company_to_price_df[company]['date'] == date]\n",
    "        entry.append(row['high'].values[0])\n",
    "        entry.append(row['low'].values[0])\n",
    "        entry.append(row['adjust_close'].values[0])\n",
    "        lags.append(entry)\n",
    "        company_index = company_to_index[company]\n",
    "        date_index = date_to_index[date]\n",
    "        for i,entry in enumerate(lags):\n",
    "            for j,price in enumerate(entry):\n",
    "                #stocks, day, lags, hi/lo/close\n",
    "                price_tensor[company_index, date_index, i, j] = price\n",
    "        lags.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-3827fcc6d0e2>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for company in tqdm_notebook(company_to_tweets.keys()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fc72f34f4b4524bbb4f7d3c0d237d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SMI tensor\n",
    "for company in tqdm_notebook(company_to_tweets.keys()):\n",
    "    dates = sorted(list(company_to_tweets[company].keys()))\n",
    "    lags = []\n",
    "    for date in dates[:5]:\n",
    "        n_tweets = len(company_to_tweets[company][date])\n",
    "        lags.append([company_to_tweets[company][date][k]['embedding'] for k in range(n_tweets)])\n",
    "    for date in dates[5:]:\n",
    "        n_tweets = len(company_to_tweets[company][date])\n",
    "        lags.append([company_to_tweets[company][date][k]['embedding'] for k in range(n_tweets)])\n",
    "        company_index = company_to_index[company]\n",
    "        date_index = date_to_index[date]\n",
    "        for i,messages in enumerate(lags):\n",
    "            for j,embedding in enumerate(messages):\n",
    "                #stocks, day, lags, tweet, embedding\n",
    "                smi_tensor[company_index, date_index, i, j, :] = embedding[:]\n",
    "        lags.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('prices.npz', price_tensor)\n",
    "np.savez_compressed('smi.npz', smi_tensor)\n",
    "\"\"\"import h5py\n",
    "with h5py.File('prices.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"prices\",  data=price_tensor)\n",
    "with h5py.File('smi.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"smi\",  data=smi_tensor)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Universal Sentence Encoder",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/hub/blob/50bbebaa248cff13e82ddf0268ed1b149ef478f2/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb",
     "timestamp": 1612309725798
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
