{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newscaffolding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49569e0edcaf4e229aed6907549726d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50af726043d641239d1a67df2e6c4762",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_775a6435db8d43c680c875962798db5a",
              "IPY_MODEL_84461fa044ca4ac3bcb6f03a8684d0d1"
            ]
          }
        },
        "50af726043d641239d1a67df2e6c4762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "775a6435db8d43c680c875962798db5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fba82edfc5b44085b5a80c9427182bc1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a00d96a5ca4e448f851e17a8dd7b2e0b"
          }
        },
        "84461fa044ca4ac3bcb6f03a8684d0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_590798787d3f4f3c9ccd6345869c57cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87/87 [00:41&lt;00:00,  2.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_babbed0841034fbdbda7da7145989218"
          }
        },
        "fba82edfc5b44085b5a80c9427182bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a00d96a5ca4e448f851e17a8dd7b2e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "590798787d3f4f3c9ccd6345869c57cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "babbed0841034fbdbda7da7145989218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e943289f6f5b415f85cc709a545c3f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_def829d589b1487ab4b22dc4873a75ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a015c594e4f4a189108ef2eacc66ff5",
              "IPY_MODEL_2ec05de1c6d44038883379805149e797"
            ]
          }
        },
        "def829d589b1487ab4b22dc4873a75ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a015c594e4f4a189108ef2eacc66ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_54f0272ba0064f65870697df3fba1e53",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3578c1faf9a74cf386cc6183a111af12"
          }
        },
        "2ec05de1c6d44038883379805149e797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2214e5a726ec46ab95fc41444e8ee6da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87/87 [01:17&lt;00:00,  1.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ebfb619a7d0414eb4ff2a8dfd1b0f56"
          }
        },
        "54f0272ba0064f65870697df3fba1e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3578c1faf9a74cf386cc6183a111af12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2214e5a726ec46ab95fc41444e8ee6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ebfb619a7d0414eb4ff2a8dfd1b0f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f067154ad0b4df69e556fc1e3aa2f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6d1c60ec8569405db6413e7dae50a5dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b808978c34d8422f9c2a39f12b2ed366",
              "IPY_MODEL_3d01ba619d204c7f89bf3123989c5490"
            ]
          }
        },
        "6d1c60ec8569405db6413e7dae50a5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b808978c34d8422f9c2a39f12b2ed366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0be1913f345448dac47819bbe53e446",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_309886273c764036a3278f5934a386ed"
          }
        },
        "3d01ba619d204c7f89bf3123989c5490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef710f1d96c9450d8bab49e0a090e8d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87/87 [00:03&lt;00:00, 26.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72eb66d2aced4a94b24bda1c0e4bbc4c"
          }
        },
        "a0be1913f345448dac47819bbe53e446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "309886273c764036a3278f5934a386ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef710f1d96c9450d8bab49e0a090e8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72eb66d2aced4a94b24bda1c0e4bbc4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59809667a87b45efad7fb29fa01ee8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_171a4fb034de48faa1c0bb992d37d8d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e551af1192b64be38a725c1f712020a9",
              "IPY_MODEL_b299e9437c3d4212babb6632b0843e94"
            ]
          }
        },
        "171a4fb034de48faa1c0bb992d37d8d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e551af1192b64be38a725c1f712020a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1514fc6ba7fa45f1ae3b4b3856c3c522",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6752f4d2fee54d34ae60fc4832bc7756"
          }
        },
        "b299e9437c3d4212babb6632b0843e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2a69752fd6e14fa6994e1d264ed4a94a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87/87 [00:02&lt;00:00, 29.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb1cf1ac2c8948aba7f5bd5591a95250"
          }
        },
        "1514fc6ba7fa45f1ae3b4b3856c3c522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6752f4d2fee54d34ae60fc4832bc7756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a69752fd6e14fa6994e1d264ed4a94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb1cf1ac2c8948aba7f5bd5591a95250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/96jonesa/CSE-517-Project/blob/main/newscaffolding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUxhN7LDSGGz"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bn0eEsGSB3N"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IchYXapSJjH"
      },
      "source": [
        "#GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-YF6GyHzwE2"
      },
      "source": [
        "##GRU\r\n",
        "This is just a wrapper around nn.GRU for the sake of consistency. Used in the Price Encoder, day-level SMI Encoder, and temporal SMI Encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OVZXsnSJH3"
      },
      "source": [
        "class GRU(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, batch_first=False):\r\n",
        "        super(GRU, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.batch_first = batch_first\r\n",
        "\r\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=self.batch_first)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        output, hn = self.gru(input)\r\n",
        "        return output, hn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRniLDIGSf5Y"
      },
      "source": [
        "#Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDM1G23a0J4V"
      },
      "source": [
        "##LinearAttention\r\n",
        "The attention mechanism used in Feng et. al. Used in the Price Encoder, day-level SMI Encoder, and temporal SMI Encoder. Given input $h$, returns\r\n",
        "$q_t = \\sum_{i=t-T}^T \\beta_i h_i$ where $\\beta_i = \\dfrac{\\exp\\left( u^T \\tanh \\left( W h_i + b \\right) \\right)}{\\sum_{k=t-T}^t \\exp\\left( u^T \\tanh \\left( W h_k + b \\right) \\right)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDJ054vAquLa"
      },
      "source": [
        "# attention weights are softmax(u^T tanh(W input + b)) where W is learned parameter matrix, u is a learned parameter vector, and b is a learned offset\r\n",
        "\r\n",
        "class LinearAttention(nn.Module):\r\n",
        "    def __init__(self, input_size, intermediate_size, weights_size):\r\n",
        "        super(LinearAttention, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.intermediate_size = intermediate_size\r\n",
        "        self.weights_size = weights_size\r\n",
        "\r\n",
        "        self.linear_1 = nn.Linear(self.input_size, self.intermediate_size, bias=True)\r\n",
        "        self.linear_2 = nn.Linear(self.intermediate_size, self.weights_size, bias=False)\r\n",
        "        self.tanh = nn.Tanh()\r\n",
        "        self.softmax = nn.Softmax(dim=2)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        intermediate = self.tanh(self.linear_1(input))\r\n",
        "        attention_weights = self.softmax(self.linear_2(intermediate))\r\n",
        "        attention_weights = attention_weights.permute(0, 2, 1)\r\n",
        "        output_features = torch.bmm(attention_weights, input)\r\n",
        "\r\n",
        "        return output_features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qkvwOlPW3kt"
      },
      "source": [
        "#Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AMUuaLR06Ph"
      },
      "source": [
        "##Blend\r\n",
        "Applies a learned bilinear transformation to the left and right vectors, then inputs the result to a ReLU non-linearity. Used to obtain Multi-Modal Encodings from Price Encodings and temporal SMI Encodings. Given Price Encodings $q_t$ and temporal SMI Encodings $c_t$, returns\r\n",
        "$x_t = \\mathcal{B} \\left( c_t, q_t \\right) = \\text{ReLU} \\left( q_t^T W c_t + b \\right)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmdq6ozMV1u8"
      },
      "source": [
        "# output is ReLU(left^T W right + b) where W is a learned paramater matrix\r\n",
        "# and b is a learned bias\r\n",
        "\r\n",
        "class Blend(nn.Module):\r\n",
        "    def __init__(self, left_size, right_size, output_size):\r\n",
        "        super(Blend, self).__init__()\r\n",
        "        self.left_size = left_size\r\n",
        "        self.right_size = right_size\r\n",
        "        self.output_size = output_size\r\n",
        "\r\n",
        "        self.bilinear = nn.Bilinear(self.left_size, self.right_size, output_size, bias=True)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "    \r\n",
        "    def forward(self, left, right):\r\n",
        "        output = self.relu(self.bilinear(left, right))\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zknLj7UautA"
      },
      "source": [
        "#Single-Headed Graph Attention Network (SGAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MQfBWhE1XR6"
      },
      "source": [
        "##SharedLinear\r\n",
        "This is just a wrapper around nn.Linear for the sake of consistency. Used to apply a shared linear transformation to all inputs of an SGAT layer. Under current implementation, this should be applied before passing inputs to SGAT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DYXTg2piK_J"
      },
      "source": [
        "# need shared learned parameter matrix W to multiply against each input vector\r\n",
        "\r\n",
        "class SharedLinear(nn.Module):\r\n",
        "    def __init__(self, input_size, output_size):\r\n",
        "        super(SharedLinear, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.output_size = output_size\r\n",
        "        \r\n",
        "        self.linear = nn.Linear(input_size, output_size, bias=False)\r\n",
        "    \r\n",
        "    def forward(self, input):\r\n",
        "        output = self.linear(input)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu7zaUMD10iy"
      },
      "source": [
        "##SGAT\r\n",
        "A single-headed GAT layer. A shared linear transform $W$ is applied to all the nodes *before* passing them as input to this module (by passing them as input to a SharedLinear layer), then a shared self-attention mechanism is applied to each node $i$ in its immediate neighborhood $\\mathcal{N}_i$. For each node $j\\in \\mathcal{N}_i$, normalized attention coefficients $\\alpha_{i,j}$ are computed to represent the importance of the relations between stocks $i$ and $j$. That is,\r\n",
        "$\\alpha_{i,j} = \\dfrac{\\exp ( \\text{LeakyReLU} ( a_w^T [ W x_i \r\n",
        "\\oplus W x_j ] ) )}{\\sum_{k\\in \\mathcal{N}_i} \\exp ( \\text{LeakyReLU} ( a_w^T [ W x_i \\oplus W x_k ] ) )}$\r\n",
        "where $\\oplus$ denotes concatenation and $a_w$ is a learned parameter matrix. An updated feature vector $z_i$ for the $i$-th stock is computed by applying these attention weights to the linearly transformed multi-modal feature vectors of all of the stocks in $\\mathcal{N}_i$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0uaOH5UW2cc"
      },
      "source": [
        "# merge code with MGAT code to form general case GAT code\r\n",
        "\r\n",
        "class SGAT(nn.Module):\r\n",
        "    def __init__(self, input_size, weights_size, leakyrelu_slope=0.01):\r\n",
        "        super(SGAT, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.weights_size = weights_size\r\n",
        "        self.leakyrelu_slope = leakyrelu_slope\r\n",
        "        \r\n",
        "        self.linear = nn.Linear(2 * input_size, weights_size, bias=False)\r\n",
        "        self.leakyrelu = nn.LeakyReLU(self.leakyrelu_slope)\r\n",
        "        self.softmax = nn.Softmax(dim=1)\r\n",
        "\r\n",
        "    def forward(self, input, neighborhoods, index):\r\n",
        "        stock = input[index]\r\n",
        "        neighborhood = neighborhoods[index]\r\n",
        "        stack_stock = stock.expand(len(neighborhood), stock.shape[0])\r\n",
        "        stack_neighbors = input[neighborhood]\r\n",
        "        cat_stock = torch.cat((stack_stock, stack_neighbors), dim=1)\r\n",
        "        attention_weights = self.softmax(self.leakyrelu(self.linear(cat_stock)))  # check this\r\n",
        "        output_features = torch.mm(attention_weights.T, stack_neighbors)  # check this\r\n",
        "\r\n",
        "        return output_features"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km8lDrqXkPIR"
      },
      "source": [
        "#MAN-SF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdXk_nhNs8Jm"
      },
      "source": [
        "class MANSF(nn.Module):\r\n",
        "    def __init__(self, T, num_stocks, gru_hidden_size, attn_inter_size, use_embed_size,\r\n",
        "                 blend_size, gat_1_inter_size, gat_2_inter_size, leakyrelu_slope, elu_alpha, U):\r\n",
        "        super(MANSF, self).__init__()\r\n",
        "        #self.to(device)\r\n",
        "        self.T = T\r\n",
        "        self.num_stocks = num_stocks\r\n",
        "        self.gru_hidden_size = gru_hidden_size\r\n",
        "        self.attn_inter_size = attn_inter_size\r\n",
        "        self.use_embed_size = use_embed_size\r\n",
        "        self.blend_size = blend_size\r\n",
        "        self.gat_1_inter_size = gat_1_inter_size\r\n",
        "        self.gat_2_inter_size = gat_2_inter_size\r\n",
        "        self.leakyrelu_slope = leakyrelu_slope\r\n",
        "        self.elu_alpha = elu_alpha\r\n",
        "        self.U = U\r\n",
        "\r\n",
        "        self.gru_p = GRU(3, gru_hidden_size, batch_first=True)\r\n",
        "        self.gru_m = GRU(use_embed_size, gru_hidden_size, batch_first=True)\r\n",
        "        self.gru_s = GRU(gru_hidden_size, gru_hidden_size, batch_first=True)\r\n",
        "        self.attn_p = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.attn_m = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.attn_s = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.blend = Blend(gru_hidden_size, gru_hidden_size, blend_size)\r\n",
        "        self.shared_linears_1 = nn.ModuleList([SharedLinear(blend_size, gat_1_inter_size) for u in range(U)])\r\n",
        "        self.shared_linears_2 = nn.ModuleList([SharedLinear(U * gat_1_inter_size, gat_2_inter_size) for u in range(U)])\r\n",
        "        self.mgat_1 = nn.ModuleList([nn.ModuleList([SGAT(gat_1_inter_size, 1, leakyrelu_slope=leakyrelu_slope) for i in range(num_stocks)]) for u in range(U)])\r\n",
        "        self.mgat_2 = nn.ModuleList([nn.ModuleList([SGAT(gat_2_inter_size, 1, leakyrelu_slope=leakyrelu_slope) for i in range(num_stocks)]) for u in range(U)])\r\n",
        "        #self.mgat_1 = []\r\n",
        "        #for u in range(U):\r\n",
        "            #sgats = []\r\n",
        "            #for i in range(num_stocks):\r\n",
        "                #sgats.append(SGAT(gat_1_inter_size, 1, leakyrelu_slope=leakyrelu_slope).to(device))\r\n",
        "            #self.mgat_1.append(sgats)\r\n",
        "            ##self.mgat_1.append(SGAT(gat_1_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "        #self.mgat_2 = []\r\n",
        "        #for u in range(U):\r\n",
        "            #sgats = []\r\n",
        "            #for i in range(num_stocks):\r\n",
        "                #sgats.append(SGAT(gat_2_inter_size, 1, leakyrelu_slope=leakyrelu_slope).to(device))\r\n",
        "            #self.mgat_2.append(sgats)\r\n",
        "            ##self.mgat_2.append(SGAT(gat_2_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        self.elu = nn.ELU(elu_alpha)\r\n",
        "        self.final_linear = nn.Linear(U * gat_2_inter_size, 1, bias=True)\r\n",
        "\r\n",
        "    # p is price data tensor of shape (num_stocks, T, 3), for the day under consideration\r\n",
        "    #\r\n",
        "    # m is smi data list of tensors of shape (num_stocks, K, use_embed_size) of length T,\r\n",
        "    #       where K is the number of tweets for the given stock on the day under consideration\r\n",
        "    #\r\n",
        "    # neighorhoods is a list of adjacency lists, where each stock is indexed with the same\r\n",
        "    #       indices they have in p and m\r\n",
        "    #\r\n",
        "    # TODO: tensorize day-level smi\r\n",
        "    # TODO: tensorize sgat \r\n",
        "    def forward(self, p, m, neighborhoods):\r\n",
        "        ## price encoding\r\n",
        "        h_p, _ = self.gru_p(p)\r\n",
        "        q = self.attn_p(h_p)\r\n",
        "\r\n",
        "        ## smi encoding (day level)\r\n",
        "        r = torch.zeros(self.num_stocks, 0, self.gru_hidden_size)\r\n",
        "        r = r.to(device)\r\n",
        "        for t in range(self.T):\r\n",
        "            h_m, _ = self.gru_m(m[t])\r\n",
        "            r_t = self.attn_m(h_m)\r\n",
        "            r = torch.cat((r, r_t), 1)\r\n",
        "\r\n",
        "        ## smi encoding (aggregate)\r\n",
        "        h_s, _ = self.gru_s(r)\r\n",
        "        c = self.attn_s(h_s)\r\n",
        "\r\n",
        "        ## blending\r\n",
        "        x = self.blend(q, c)\r\n",
        "\r\n",
        "        ## reshaping (eliminating superfluous dimension)\r\n",
        "        x = x.view(x.shape[0], x.shape[2])\r\n",
        "\r\n",
        "        ## first gat layer\r\n",
        "        #  first head\r\n",
        "        shared_linear = self.shared_linears_1[0]\r\n",
        "        Wx = shared_linear(x)\r\n",
        "        #sgat = self.mgat_1[0]\r\n",
        "        sgat = self.mgat_1[0][0]\r\n",
        "        z = sgat(Wx, neighborhoods, 0)\r\n",
        "        z = self.elu(z)\r\n",
        "\r\n",
        "        for i in range(1, self.num_stocks):\r\n",
        "            sgat = self.mgat_1[0][i]  # this is the fix to the proceeding TODO\r\n",
        "            z_i = sgat(Wx, neighborhoods, i)  # TODO: use fresh SGAT for each stock\r\n",
        "            z_i = self.elu(z_i)\r\n",
        "            z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "        #  remaining heads\r\n",
        "        for u in range(1, self.U):\r\n",
        "            shared_linear = self.shared_linears_1[u]\r\n",
        "            Wx = shared_linear(x)\r\n",
        "            #sgat = self.mgat_1[u]\r\n",
        "            sgat = self.mgat_1[u][0]\r\n",
        "            z_u = sgat(Wx, neighborhoods, 0)\r\n",
        "            z_u = self.elu(z_u)\r\n",
        "\r\n",
        "            for i in range(1, self.num_stocks):\r\n",
        "                sgat = self.mgat_1[u][i]\r\n",
        "                z_u_i = sgat(Wx, neighborhoods, i)\r\n",
        "                z_u_i = self.elu(z_u_i)\r\n",
        "                z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "            \r\n",
        "            z = torch.cat((z, z_u), 1)\r\n",
        "        \r\n",
        "        ## second gat layer\r\n",
        "        #  first head\r\n",
        "        shared_linear = self.shared_linears_2[0]\r\n",
        "        Wx = shared_linear(z)\r\n",
        "        #sgat = self.mgat_2[0]\r\n",
        "        sgat = self.mgat_2[0][0]\r\n",
        "        new_z = sgat(Wx, neighborhoods, 0)\r\n",
        "        new_z = self.sigmoid(new_z)\r\n",
        "\r\n",
        "        for i in range(1, self.num_stocks):\r\n",
        "            sgat = self.mgat_2[0][i]\r\n",
        "            new_z_i = sgat(Wx, neighborhoods, i)\r\n",
        "            new_z_i = self.sigmoid(new_z_i)\r\n",
        "            new_z = torch.cat((new_z, new_z_i), 0)\r\n",
        "\r\n",
        "        #  remaining heads\r\n",
        "        for u in range(1, self.U):\r\n",
        "            shared_linear = self.shared_linears_2[u]\r\n",
        "            Wx = shared_linear(z)\r\n",
        "            #sgat = self.mgat_2[u]\r\n",
        "            sgat = self.mgat_2[u][0]\r\n",
        "            new_z_u = sgat(Wx, neighborhoods, 0)\r\n",
        "            new_z_u = self.sigmoid(new_z_u)\r\n",
        "\r\n",
        "            for i in range(1, self.num_stocks):\r\n",
        "                sgat = self.mgat_2[u][i]\r\n",
        "                new_z_u_i = sgat(Wx, neighborhoods, i)\r\n",
        "                new_z_u_i = self.sigmoid(new_z_u_i)\r\n",
        "                new_z_u = torch.cat((new_z_u, new_z_u_i), 0)\r\n",
        "            \r\n",
        "            new_z = torch.cat((new_z, new_z_u), 1)\r\n",
        "        \r\n",
        "        ## final layer\r\n",
        "        y = self.sigmoid(self.final_linear(new_z))\r\n",
        "\r\n",
        "        ## return result\r\n",
        "        return y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6L6LtO021c-"
      },
      "source": [
        "#Real Data Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVP3X7na21C_"
      },
      "source": [
        "!pip3 install --quiet \"tensorflow-hub>=0.7.0\"\r\n",
        "!pip3 install --quiet seaborn"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUsNUekr6cGU",
        "outputId": "41e2a766-e536-479e-dd94-d672f4f76e1c"
      },
      "source": [
        "!unzip /content/stocknet-dataset-master.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/stocknet-dataset-master.zip\n",
            "330708b5ddc359961078bef469f43f48992fd6e4\n",
            "replace stocknet-dataset-master/LICENSE? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trqE3r4r3DHp"
      },
      "source": [
        "from absl import logging\r\n",
        "\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import re\r\n",
        "import seaborn as sns\r\n",
        "import json\r\n",
        "import itertools\r\n",
        "import pandas as pd\r\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh3x2jjU3Fyi"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9pUBxxA3Iau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3552578-4ce6-4f86-ceee-a5169b89c4aa"
      },
      "source": [
        "tf.disable_v2_behavior()\r\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe5qiz4i3KeL"
      },
      "source": [
        "stocknet_dataset_filepath = './stocknet-dataset-master'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "49569e0edcaf4e229aed6907549726d3",
            "50af726043d641239d1a67df2e6c4762",
            "775a6435db8d43c680c875962798db5a",
            "84461fa044ca4ac3bcb6f03a8684d0d1",
            "fba82edfc5b44085b5a80c9427182bc1",
            "a00d96a5ca4e448f851e17a8dd7b2e0b",
            "590798787d3f4f3c9ccd6345869c57cd",
            "babbed0841034fbdbda7da7145989218"
          ]
        },
        "id": "ucyox-J-3MQb",
        "outputId": "bc6975b1-5d81-4013-973f-b96e80693df1"
      },
      "source": [
        "preprocessed_prices_filepath = stocknet_dataset_filepath + '/price/preprocessed'\r\n",
        "preprocessed_tweets_filepath = stocknet_dataset_filepath + '/tweet/preprocessed'\r\n",
        "\r\n",
        "company_to_price_df = {}\r\n",
        "company_to_tweets = {}\r\n",
        "\r\n",
        "for filename in os.listdir(preprocessed_prices_filepath):\r\n",
        "    with open(preprocessed_prices_filepath + '/' + filename) as file:\r\n",
        "        company_name = filename.split('.')[0]\r\n",
        "        \r\n",
        "        # Not enough data for GMRE\r\n",
        "        if company_name == 'GMRE':\r\n",
        "            continue\r\n",
        "        df = pd.read_csv(file, sep='\\t')\r\n",
        "        df.columns = ['date', 'open', 'high', 'low', 'close', 'adjust_close', 'volume']\r\n",
        "        company_to_price_df[company_name] = df.dropna()\r\n",
        "\r\n",
        "for filename in tqdm_notebook(os.listdir(preprocessed_tweets_filepath)):\r\n",
        "    company_name = filename.split('.')[0]\r\n",
        "    dates_to_tweets = {}\r\n",
        "    for tweet_filename in os.listdir(preprocessed_tweets_filepath + '/' + filename):\r\n",
        "        with open(preprocessed_tweets_filepath + '/' + filename + '/' + tweet_filename) as file:\r\n",
        "            list_of_tweets = []\r\n",
        "            for line in file:\r\n",
        "                tweet_json = json.loads(line)\r\n",
        "                list_of_tweets.append(tweet_json)\r\n",
        "            dates_to_tweets[tweet_filename] = list_of_tweets\r\n",
        "    company_to_tweets[company_name] = dates_to_tweets"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49569e0edcaf4e229aed6907549726d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wej3tdxH3OBe",
        "outputId": "b792517e-6185-4108-a89a-969b00f1168d"
      },
      "source": [
        "#print(company_to_tweets.keys())\r\n",
        "#print(dates_to_tweets.keys())\r\n",
        "print(company_to_tweets['AAPL']['2015-10-02'][0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['rt', '$', 'tsla', 'hft', 'algos', 'triggered', 'buy', 'in', 'sigma-x', ',', 'crossfinder', ',', 'ats', ',', 'lx', '@', '08:28', ',', 'p', '/', 't', '245.00', 'quant', '$', 'msft', '$', 'fb', '$', 'gpro', '$', 'amzn', '$', 'goog', '$', 'aapl', '$', 'nflx', '$', 'qqq'], 'created_at': 'Fri Oct 02 12:29:15 +0000 2015', 'user_id_str': '242469235'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKLN9Kao3QE7"
      },
      "source": [
        "# Reduce logging output.\r\n",
        "logging.set_verbosity(logging.ERROR)\r\n",
        "tf.get_logger().setLevel(logging.ERROR)\r\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\r\n",
        "\r\n",
        "# Import the Universal Sentence Encoder's TF Hub module\r\n",
        "def embed_useT(module):\r\n",
        "    with tf.Graph().as_default():\r\n",
        "        sentences = tf.placeholder(tf.string)\r\n",
        "        embed = hub.Module(module)\r\n",
        "        embeddings = embed(sentences)\r\n",
        "        session = tf.train.MonitoredSession()\r\n",
        "    return lambda x: session.run(embeddings, {sentences: x})\r\n",
        "embed_fn = embed_useT(module_url)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3RNGgy_3SF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "e943289f6f5b415f85cc709a545c3f6a",
            "def829d589b1487ab4b22dc4873a75ff",
            "8a015c594e4f4a189108ef2eacc66ff5",
            "2ec05de1c6d44038883379805149e797",
            "54f0272ba0064f65870697df3fba1e53",
            "3578c1faf9a74cf386cc6183a111af12",
            "2214e5a726ec46ab95fc41444e8ee6da",
            "9ebfb619a7d0414eb4ff2a8dfd1b0f56"
          ]
        },
        "outputId": "e84f0252-ab3b-4cd4-dc79-5d60c112d5cf"
      },
      "source": [
        "# Generate embeddings\r\n",
        "for company in tqdm_notebook(company_to_tweets.keys()):\r\n",
        "  for date in company_to_tweets[company].keys():\r\n",
        "    messages = []\r\n",
        "    for j in range(len(company_to_tweets[company][date])):\r\n",
        "      messages.append(' '.join(company_to_tweets[company][date][j]['text']))\r\n",
        "    message_embeddings = embed_fn(messages)\r\n",
        "    for k in range(len(company_to_tweets[company][date])):\r\n",
        "      company_to_tweets[company][date][k]['embedding'] = list(message_embeddings[k])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e943289f6f5b415f85cc709a545c3f6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xVaLHrQ3UyO"
      },
      "source": [
        "# Create date mapping\r\n",
        "date_universe = set()\r\n",
        "for company in company_to_price_df.keys():\r\n",
        "    date_universe = date_universe.union(set(company_to_price_df[company].date))\r\n",
        "for company in company_to_tweets.keys():\r\n",
        "    date_universe = date_universe.union(set(company_to_tweets[company].keys()))\r\n",
        "date_universe = sorted(list(date_universe))\r\n",
        "index_to_date = {i-5:d for i,d in enumerate(date_universe)}\r\n",
        "date_to_index = {d:i-5 for i,d in enumerate(date_universe)}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qM0_yTp3Wdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f99073-d626-4622-fdd4-8f8de2096f6d"
      },
      "source": [
        "# Calculate dimensions for tensor\r\n",
        "n_stocks = len(company_to_tweets.keys())\r\n",
        "n_days = len(date_universe)\r\n",
        "max_tweets = 0\r\n",
        "for c,d in itertools.product(company_to_tweets.keys(), date_universe):\r\n",
        "    if d in company_to_tweets[c]:\r\n",
        "        max_tweets = max(max_tweets, len(company_to_tweets[c][d]))\r\n",
        "# Create index mapping for stocks alphabetically\r\n",
        "company_to_index = {c:i for i,c in enumerate(sorted(list(company_to_tweets.keys())))}\r\n",
        "# print dimensions\r\n",
        "print(n_stocks)\r\n",
        "print(n_days)\r\n",
        "print(max_tweets)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87\n",
            "1473\n",
            "555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFTIq-5s9wnc"
      },
      "source": [
        "n_days = 6"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxsK88qJ3ZXv"
      },
      "source": [
        "# Construct tensors\r\n",
        "price_tensor = np.zeros((n_stocks, n_days - 5, 6, 3))\r\n",
        "smi_tensor = np.zeros((n_stocks, n_days - 5, 6, max_tweets, 512))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rCyn-Yy3bqT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "6f067154ad0b4df69e556fc1e3aa2f55",
            "6d1c60ec8569405db6413e7dae50a5dd",
            "b808978c34d8422f9c2a39f12b2ed366",
            "3d01ba619d204c7f89bf3123989c5490",
            "a0be1913f345448dac47819bbe53e446",
            "309886273c764036a3278f5934a386ed",
            "ef710f1d96c9450d8bab49e0a090e8d7",
            "72eb66d2aced4a94b24bda1c0e4bbc4c"
          ]
        },
        "outputId": "3551f88b-828e-4ddf-8210-96db00d5ac0a"
      },
      "source": [
        "# SMI tensor\r\n",
        "for company in tqdm_notebook(company_to_price_df.keys()):\r\n",
        "    dates = sorted(list(company_to_price_df[company].date))\r\n",
        "    lags = []\r\n",
        "    for date in dates[:5]:\r\n",
        "        entry = []\r\n",
        "        row = company_to_price_df[company].loc[company_to_price_df[company]['date'] == date]\r\n",
        "        entry.append(row['high'].values[0])\r\n",
        "        entry.append(row['low'].values[0])\r\n",
        "        entry.append(row['adjust_close'].values[0])\r\n",
        "        lags.append(entry)\r\n",
        "    for date in dates[5:6]:\r\n",
        "        entry = []\r\n",
        "        row = company_to_price_df[company].loc[company_to_price_df[company]['date'] == date]\r\n",
        "        entry.append(row['high'].values[0])\r\n",
        "        entry.append(row['low'].values[0])\r\n",
        "        entry.append(row['adjust_close'].values[0])\r\n",
        "        lags.append(entry)\r\n",
        "        company_index = company_to_index[company]\r\n",
        "        date_index = date_to_index[date]\r\n",
        "        date_index = 0\r\n",
        "        for i,entry in enumerate(lags):\r\n",
        "            for j,price in enumerate(entry):\r\n",
        "                #stocks, day, lags, hi/lo/close\r\n",
        "                price_tensor[company_index, date_index, i, j] = price\r\n",
        "        lags.pop(0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f067154ad0b4df69e556fc1e3aa2f55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BnZ_Shm3dRf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "59809667a87b45efad7fb29fa01ee8d2",
            "171a4fb034de48faa1c0bb992d37d8d1",
            "e551af1192b64be38a725c1f712020a9",
            "b299e9437c3d4212babb6632b0843e94",
            "1514fc6ba7fa45f1ae3b4b3856c3c522",
            "6752f4d2fee54d34ae60fc4832bc7756",
            "2a69752fd6e14fa6994e1d264ed4a94a",
            "eb1cf1ac2c8948aba7f5bd5591a95250"
          ]
        },
        "outputId": "e0db4862-5f8a-4821-8a52-6e8fc559f5a3"
      },
      "source": [
        "# SMI tensor\r\n",
        "for company in tqdm_notebook(company_to_tweets.keys()):\r\n",
        "    dates = sorted(list(company_to_tweets[company].keys()))\r\n",
        "    lags = []\r\n",
        "    for date in dates[:5]:\r\n",
        "        n_tweets = len(company_to_tweets[company][date])\r\n",
        "        lags.append([company_to_tweets[company][date][k]['embedding'] for k in range(n_tweets)])\r\n",
        "    for date in dates[5:6]:\r\n",
        "        n_tweets = len(company_to_tweets[company][date])\r\n",
        "        lags.append([company_to_tweets[company][date][k]['embedding'] for k in range(n_tweets)])\r\n",
        "        company_index = company_to_index[company]\r\n",
        "        date_index = date_to_index[date]\r\n",
        "        date_index = 0\r\n",
        "        for i,messages in enumerate(lags):\r\n",
        "            for j,embedding in enumerate(messages):\r\n",
        "                #stocks, day, lags, tweet, embedding\r\n",
        "                smi_tensor[company_index, date_index, i, j, :] = embedding[:]\r\n",
        "        lags.pop(0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59809667a87b45efad7fb29fa01ee8d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6HdbQreXd6q",
        "outputId": "78b41fea-d575-4763-9fee-2c2e77d79051"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\r\n",
        "\r\n",
        "print(device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0hV3C9wDpBb"
      },
      "source": [
        "price_tensor = torch.from_numpy(price_tensor)\r\n",
        "smi_tensor = torch.from_numpy(smi_tensor)\r\n",
        "\r\n",
        "price_tensor = price_tensor.type(torch.FloatTensor)\r\n",
        "smi_tensor = smi_tensor.type(torch.FloatTensor)\r\n",
        "\r\n",
        "price_tensor = price_tensor.to(device)\r\n",
        "smi_tensor = smi_tensor.to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4EpFroQ3ewM"
      },
      "source": [
        "p = price_tensor.view(n_stocks, 6, 3)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwSFIAGP637V"
      },
      "source": [
        "smi_tensor = smi_tensor.view(n_stocks, 6, max_tweets, 512)\r\n",
        "\r\n",
        "smi_tensor = smi_tensor.permute(1, 0, 2, 3)\r\n",
        "\r\n",
        "m = []\r\n",
        "for t in range(6):\r\n",
        "    m.append(smi_tensor[t])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxzrYMO07txE"
      },
      "source": [
        "neighborhoods = []\r\n",
        "for i in range(n_stocks):\r\n",
        "    if i % 2 == 0:\r\n",
        "        #neighborhood = [i]\r\n",
        "        if i == n_stocks - 1:\r\n",
        "            neighborhood = [i]\r\n",
        "            neighborhood = torch.tensor(neighborhood)\r\n",
        "            neighborhood = neighborhood.to(device)\r\n",
        "            neighborhoods.append(neighborhood)\r\n",
        "        else:\r\n",
        "            neighborhood = [i, i + 1]\r\n",
        "            neighborhood = torch.tensor(neighborhood)\r\n",
        "            neighborhood = neighborhood.to(device)\r\n",
        "            neighborhoods.append(neighborhood)\r\n",
        "    else:\r\n",
        "        #neighborhood = [i]\r\n",
        "        neighborhood = [i - 1, i]\r\n",
        "        neighborhood = torch.tensor(neighborhood)\r\n",
        "        neighborhood = neighborhood.to(device)\r\n",
        "        neighborhoods.append(neighborhood)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmwXRs1375Gm"
      },
      "source": [
        "mansf = MANSF(T=6,\r\n",
        "              num_stocks=n_stocks,\r\n",
        "              gru_hidden_size=64,\r\n",
        "              attn_inter_size=32,\r\n",
        "              use_embed_size=512,\r\n",
        "              blend_size=32,\r\n",
        "              gat_1_inter_size=32,\r\n",
        "              gat_2_inter_size=32,\r\n",
        "              leakyrelu_slope=0.01,\r\n",
        "              elu_alpha=1.0,\r\n",
        "              U=8)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e9SgO_QGK9C"
      },
      "source": [
        "mansf = mansf.to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixq4bt6n79ev"
      },
      "source": [
        "y = mansf(p, m, neighborhoods)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eIjnLKqATqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc63bac-5ad8-4cec-eaef-9c8aee629fde"
      },
      "source": [
        "print(y)  # initial predictions without training"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4057],\n",
            "        [0.4057],\n",
            "        [0.4063],\n",
            "        [0.4063],\n",
            "        [0.4132],\n",
            "        [0.4132],\n",
            "        [0.3374],\n",
            "        [0.3374],\n",
            "        [0.4103],\n",
            "        [0.4103],\n",
            "        [0.3562],\n",
            "        [0.3562],\n",
            "        [0.3621],\n",
            "        [0.3621],\n",
            "        [0.3935],\n",
            "        [0.3935],\n",
            "        [0.3847],\n",
            "        [0.3847],\n",
            "        [0.3430],\n",
            "        [0.3430],\n",
            "        [0.3876],\n",
            "        [0.3876],\n",
            "        [0.4065],\n",
            "        [0.4065],\n",
            "        [0.3872],\n",
            "        [0.3872],\n",
            "        [0.4008],\n",
            "        [0.4008],\n",
            "        [0.4006],\n",
            "        [0.4006],\n",
            "        [0.3938],\n",
            "        [0.3938],\n",
            "        [0.3955],\n",
            "        [0.3955],\n",
            "        [0.3742],\n",
            "        [0.3742],\n",
            "        [0.3986],\n",
            "        [0.3986],\n",
            "        [0.3948],\n",
            "        [0.3948],\n",
            "        [0.4079],\n",
            "        [0.4079],\n",
            "        [0.3888],\n",
            "        [0.3888],\n",
            "        [0.3881],\n",
            "        [0.3881],\n",
            "        [0.3964],\n",
            "        [0.3964],\n",
            "        [0.4099],\n",
            "        [0.4099],\n",
            "        [0.4011],\n",
            "        [0.4011],\n",
            "        [0.4065],\n",
            "        [0.4065],\n",
            "        [0.4011],\n",
            "        [0.4011],\n",
            "        [0.3467],\n",
            "        [0.3467],\n",
            "        [0.4090],\n",
            "        [0.4090],\n",
            "        [0.4046],\n",
            "        [0.4046],\n",
            "        [0.4023],\n",
            "        [0.4023],\n",
            "        [0.3511],\n",
            "        [0.3511],\n",
            "        [0.3941],\n",
            "        [0.3941],\n",
            "        [0.3878],\n",
            "        [0.3878],\n",
            "        [0.4082],\n",
            "        [0.4082],\n",
            "        [0.4019],\n",
            "        [0.4019],\n",
            "        [0.3695],\n",
            "        [0.3695],\n",
            "        [0.4053],\n",
            "        [0.4053],\n",
            "        [0.4081],\n",
            "        [0.4081],\n",
            "        [0.4065],\n",
            "        [0.4065],\n",
            "        [0.4000],\n",
            "        [0.4000],\n",
            "        [0.4038],\n",
            "        [0.4038],\n",
            "        [0.4086]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSM4fhHSBPaw"
      },
      "source": [
        "Y = torch.zeros(n_stocks, 1)\r\n",
        "\r\n",
        "for i in range(n_stocks):\r\n",
        "    if p[i][5][2] > 0:\r\n",
        "        Y[i][0] = 1.0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYwSOO_6GVg9"
      },
      "source": [
        "Y = Y.to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qQl39tGYVVp"
      },
      "source": [
        "optimizer = optim.Adam(mansf.parameters())\r\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iMQcxMLAT3D",
        "outputId": "64bac9d4-2184-4fcd-9dcb-a2ad369ff99f"
      },
      "source": [
        "for epoch in range(100):\r\n",
        "    mansf.train()\r\n",
        "    y = mansf(p, m, neighborhoods)\r\n",
        "    loss = loss_fn(y.view(-1), Y.view(-1))\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    print(epoch, loss)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.7580, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "1 tensor(0.6646, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "2 tensor(0.6460, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "3 tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "4 tensor(0.6293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "5 tensor(0.6497, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "6 tensor(0.6080, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "7 tensor(0.6030, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "8 tensor(0.5852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "9 tensor(0.5781, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "10 tensor(0.5726, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "11 tensor(0.5662, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "12 tensor(0.5629, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "13 tensor(0.5556, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "14 tensor(0.5547, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "15 tensor(0.5475, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "16 tensor(0.5462, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "17 tensor(0.5411, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "18 tensor(0.5367, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "19 tensor(0.5343, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "20 tensor(0.5297, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "21 tensor(0.5273, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "22 tensor(0.5250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "23 tensor(0.5217, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "24 tensor(0.5191, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "25 tensor(0.5164, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "26 tensor(0.5134, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "27 tensor(0.5110, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "28 tensor(0.5090, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "29 tensor(0.5096, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "30 tensor(0.5104, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "31 tensor(0.5005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "32 tensor(0.4942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "33 tensor(0.4966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "34 tensor(0.4965, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "35 tensor(0.4879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "36 tensor(0.4803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "37 tensor(0.4812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "38 tensor(0.4885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "39 tensor(0.4835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "40 tensor(0.4697, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "41 tensor(0.4673, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "42 tensor(0.4738, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "43 tensor(0.4739, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "44 tensor(0.4577, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "45 tensor(0.4524, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "46 tensor(0.4578, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "47 tensor(0.4517, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "48 tensor(0.4414, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "49 tensor(0.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "50 tensor(0.4420, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "51 tensor(0.4586, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "52 tensor(0.4646, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "53 tensor(0.4434, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "54 tensor(0.4339, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "55 tensor(0.4451, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "56 tensor(0.4227, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "57 tensor(0.4381, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "58 tensor(0.4368, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "59 tensor(0.4176, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "60 tensor(0.4320, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "61 tensor(0.4134, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "62 tensor(0.4242, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "63 tensor(0.4123, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "64 tensor(0.4139, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "65 tensor(0.4148, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "66 tensor(0.4040, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "67 tensor(0.4120, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "68 tensor(0.4016, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "69 tensor(0.4040, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "70 tensor(0.4032, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "71 tensor(0.3967, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "72 tensor(0.4006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "73 tensor(0.3944, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "74 tensor(0.3940, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "75 tensor(0.3943, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "76 tensor(0.3888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "77 tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "78 tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "79 tensor(0.3846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "80 tensor(0.3858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "81 tensor(0.3835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "82 tensor(0.3802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "83 tensor(0.3807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "84 tensor(0.3794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "85 tensor(0.3763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "86 tensor(0.3759, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "87 tensor(0.3751, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "88 tensor(0.3727, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "89 tensor(0.3713, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "90 tensor(0.3711, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "91 tensor(0.3696, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "92 tensor(0.3676, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "93 tensor(0.3666, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "94 tensor(0.3660, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "95 tensor(0.3648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "96 tensor(0.3629, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "97 tensor(0.3614, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "98 tensor(0.3603, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
            "99 tensor(0.3597, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diT-iBaZAeI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33126f8-11db-454c-868f-819285499694"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9819],\n",
            "        [0.9819],\n",
            "        [0.7770],\n",
            "        [0.7770],\n",
            "        [0.1094],\n",
            "        [0.1094],\n",
            "        [0.0404],\n",
            "        [0.0404],\n",
            "        [0.0452],\n",
            "        [0.0452],\n",
            "        [0.6020],\n",
            "        [0.6020],\n",
            "        [0.9798],\n",
            "        [0.9798],\n",
            "        [0.0568],\n",
            "        [0.0568],\n",
            "        [0.3981],\n",
            "        [0.3981],\n",
            "        [0.9647],\n",
            "        [0.9647],\n",
            "        [0.9818],\n",
            "        [0.9818],\n",
            "        [0.9755],\n",
            "        [0.9755],\n",
            "        [0.9708],\n",
            "        [0.9708],\n",
            "        [0.3971],\n",
            "        [0.3971],\n",
            "        [0.3332],\n",
            "        [0.3332],\n",
            "        [0.8231],\n",
            "        [0.8231],\n",
            "        [0.3490],\n",
            "        [0.3490],\n",
            "        [0.4906],\n",
            "        [0.4906],\n",
            "        [0.5822],\n",
            "        [0.5822],\n",
            "        [0.9822],\n",
            "        [0.9822],\n",
            "        [0.4293],\n",
            "        [0.4293],\n",
            "        [0.9624],\n",
            "        [0.9624],\n",
            "        [0.9452],\n",
            "        [0.9452],\n",
            "        [0.3793],\n",
            "        [0.3793],\n",
            "        [0.1261],\n",
            "        [0.1261],\n",
            "        [0.5712],\n",
            "        [0.5712],\n",
            "        [0.3579],\n",
            "        [0.3579],\n",
            "        [0.3770],\n",
            "        [0.3770],\n",
            "        [0.4904],\n",
            "        [0.4904],\n",
            "        [0.0597],\n",
            "        [0.0597],\n",
            "        [0.5417],\n",
            "        [0.5417],\n",
            "        [0.0316],\n",
            "        [0.0316],\n",
            "        [0.9695],\n",
            "        [0.9695],\n",
            "        [0.9297],\n",
            "        [0.9297],\n",
            "        [0.9817],\n",
            "        [0.9817],\n",
            "        [0.4879],\n",
            "        [0.4879],\n",
            "        [0.6168],\n",
            "        [0.6168],\n",
            "        [0.9015],\n",
            "        [0.9015],\n",
            "        [0.6894],\n",
            "        [0.6894],\n",
            "        [0.1829],\n",
            "        [0.1829],\n",
            "        [0.8678],\n",
            "        [0.8678],\n",
            "        [0.9814],\n",
            "        [0.9814],\n",
            "        [0.5389],\n",
            "        [0.5389],\n",
            "        [0.2780]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjG7nAHhLP6W"
      },
      "source": [
        "ycatY = torch.cat((y, Y), dim=1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lNhoK16LURh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddb1f8d-1fc3-4df1-a1a8-8e3efdb55a00"
      },
      "source": [
        "print(ycatY)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9819, 1.0000],\n",
            "        [0.9819, 1.0000],\n",
            "        [0.7770, 1.0000],\n",
            "        [0.7770, 1.0000],\n",
            "        [0.1094, 0.0000],\n",
            "        [0.1094, 0.0000],\n",
            "        [0.0404, 0.0000],\n",
            "        [0.0404, 0.0000],\n",
            "        [0.0452, 0.0000],\n",
            "        [0.0452, 0.0000],\n",
            "        [0.6020, 1.0000],\n",
            "        [0.6020, 0.0000],\n",
            "        [0.9798, 1.0000],\n",
            "        [0.9798, 1.0000],\n",
            "        [0.0568, 0.0000],\n",
            "        [0.0568, 0.0000],\n",
            "        [0.3981, 0.0000],\n",
            "        [0.3981, 1.0000],\n",
            "        [0.9647, 1.0000],\n",
            "        [0.9647, 1.0000],\n",
            "        [0.9818, 1.0000],\n",
            "        [0.9818, 1.0000],\n",
            "        [0.9755, 1.0000],\n",
            "        [0.9755, 1.0000],\n",
            "        [0.9708, 1.0000],\n",
            "        [0.9708, 1.0000],\n",
            "        [0.3971, 0.0000],\n",
            "        [0.3971, 1.0000],\n",
            "        [0.3332, 1.0000],\n",
            "        [0.3332, 0.0000],\n",
            "        [0.8231, 0.0000],\n",
            "        [0.8231, 1.0000],\n",
            "        [0.3490, 0.0000],\n",
            "        [0.3490, 1.0000],\n",
            "        [0.4906, 0.0000],\n",
            "        [0.4906, 1.0000],\n",
            "        [0.5822, 1.0000],\n",
            "        [0.5822, 0.0000],\n",
            "        [0.9822, 1.0000],\n",
            "        [0.9822, 1.0000],\n",
            "        [0.4293, 0.0000],\n",
            "        [0.4293, 0.0000],\n",
            "        [0.9624, 1.0000],\n",
            "        [0.9624, 1.0000],\n",
            "        [0.9452, 1.0000],\n",
            "        [0.9452, 1.0000],\n",
            "        [0.3793, 0.0000],\n",
            "        [0.3793, 0.0000],\n",
            "        [0.1261, 0.0000],\n",
            "        [0.1261, 0.0000],\n",
            "        [0.5712, 1.0000],\n",
            "        [0.5712, 0.0000],\n",
            "        [0.3579, 0.0000],\n",
            "        [0.3579, 1.0000],\n",
            "        [0.3770, 0.0000],\n",
            "        [0.3770, 0.0000],\n",
            "        [0.4904, 0.0000],\n",
            "        [0.4904, 1.0000],\n",
            "        [0.0597, 0.0000],\n",
            "        [0.0597, 0.0000],\n",
            "        [0.5417, 0.0000],\n",
            "        [0.5417, 1.0000],\n",
            "        [0.0316, 0.0000],\n",
            "        [0.0316, 0.0000],\n",
            "        [0.9695, 1.0000],\n",
            "        [0.9695, 1.0000],\n",
            "        [0.9297, 1.0000],\n",
            "        [0.9297, 1.0000],\n",
            "        [0.9817, 1.0000],\n",
            "        [0.9817, 1.0000],\n",
            "        [0.4879, 0.0000],\n",
            "        [0.4879, 1.0000],\n",
            "        [0.6168, 0.0000],\n",
            "        [0.6168, 1.0000],\n",
            "        [0.9015, 1.0000],\n",
            "        [0.9015, 1.0000],\n",
            "        [0.6894, 1.0000],\n",
            "        [0.6894, 0.0000],\n",
            "        [0.1829, 0.0000],\n",
            "        [0.1829, 1.0000],\n",
            "        [0.8678, 1.0000],\n",
            "        [0.8678, 1.0000],\n",
            "        [0.9814, 1.0000],\n",
            "        [0.9814, 1.0000],\n",
            "        [0.5389, 1.0000],\n",
            "        [0.5389, 1.0000],\n",
            "        [0.2780, 0.0000]], device='cuda:0', grad_fn=<CatBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpDQJ9m6FoJC"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGJlWH03F6Vm"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOrNDPkGF7Lx"
      },
      "source": [
        "p = torch.tensor([[[1.5, 1.8, 1.2], [1.7, 1.9, 1.3]], [[0.8, 0.9, 0.6], [0.6, 0.7, 0.4]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5RpydUnHCY_"
      },
      "source": [
        "print(p.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajvv409nHEQW"
      },
      "source": [
        "m = [torch.zeros(2,1,64),torch.zeros(2,1,64)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsW9psWTH5Q0"
      },
      "source": [
        "print(m[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm8MhsktIEmL"
      },
      "source": [
        "neighborhoods = [[0,1],[0,1,]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHhPTGwtITTJ"
      },
      "source": [
        "Y = torch.tensor([[1.0],[0.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAxznczuI1Mk"
      },
      "source": [
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d71ifgz-I2HP"
      },
      "source": [
        "mansf = MANSF(T=2,\r\n",
        "              num_stocks=2,\r\n",
        "              gru_hidden_size=64,\r\n",
        "              attn_inter_size=32,\r\n",
        "              use_embed_size=64,\r\n",
        "              blend_size=32,\r\n",
        "              gat_1_inter_size=32,\r\n",
        "              gat_2_inter_size=32,\r\n",
        "              leakyrelu_slope=0.01,\r\n",
        "              elu_alpha=1.0,\r\n",
        "              U=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPqWqHO3JSes"
      },
      "source": [
        "y = mansf(p, m, neighborhoods)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvi0n_YKF0x"
      },
      "source": [
        "print(y)  # initial predictions without training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln1XgFXjKXL2"
      },
      "source": [
        "optimizer = optim.Adam(mansf.parameters())\r\n",
        "loss_fn = nn.BCELoss()\r\n",
        "\r\n",
        "for epoch in range(100):\r\n",
        "    mansf.train()\r\n",
        "    y = mansf(p, m, neighborhoods)\r\n",
        "    loss = loss_fn(y.view(-1), Y.view(-1))\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    print(y[0].item(), y[1].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laFsXLtlL6Ai"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrZFtsoENPHE"
      },
      "source": [
        "p_test = torch.tensor([[[1.3, 1.6, 1.0], [1.4, 1.5, 1.2]], [[0.83, 0.91, 0.67], [0.75, 0.89, 0.56]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWn4om-ENfys"
      },
      "source": [
        "m_test = [torch.zeros(2,1,64),torch.zeros(2,1,64)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUv2f2ofNizl"
      },
      "source": [
        "y_test = mansf(p_test, m_test, neighborhoods)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnvXt58hNone"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7WqGMFQOZA6"
      },
      "source": [
        "p_test2 = torch.tensor([[[0.83, 0.91, 0.67], [0.75, 0.89, 0.56]], [[1.3, 1.6, 1.0], [1.4, 1.5, 1.2]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gshnkeQJOfDl"
      },
      "source": [
        "m_test2 = [torch.zeros(2,1,64),torch.zeros(2,1,64)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieovkdZHOgWs"
      },
      "source": [
        "y_test2 = mansf(p_test2, m_test2, neighborhoods)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOzt8_FAOiCc"
      },
      "source": [
        "print(y_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxCeTPkshTiD"
      },
      "source": [
        "#Sandbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXK3JLoK4SgP"
      },
      "source": [
        "##Price Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrA5qKZwhTK7"
      },
      "source": [
        "T = 5  # number of days in lookback window\r\n",
        "batch_size = 4\r\n",
        "gru_p_hidden_size = 64\r\n",
        "\r\n",
        "p = torch.rand(batch_size, T, 3)  # p_i = [p_i^c, p_i^h, p_i^l], not bothering to normalize for shape tests\r\n",
        "\r\n",
        "print('p.shape', p.shape)\r\n",
        "\r\n",
        "h_p_0 = torch.randn(1, batch_size, gru_p_hidden_size)  # randomly initialized initial hidden state\r\n",
        "gru_p = GRU(3, gru_p_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "h_p, h_p_n = gru_p(p, h_p_0)\r\n",
        "\r\n",
        "print('h_p.shape', h_p.shape)\r\n",
        "print('h_p_n.shape', h_p_n.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXkpe2m1oE7p"
      },
      "source": [
        "attn_p_intermediate_size = 10\r\n",
        "\r\n",
        "attn_p = LinearAttention(gru_p_hidden_size, attn_p_intermediate_size, 1)\r\n",
        "\r\n",
        "q = attn_p(h_p)\r\n",
        "\r\n",
        "print('q.shape', q.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfVX_mwE4Upm"
      },
      "source": [
        "##SMI Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpbYUa13FP2T"
      },
      "source": [
        "K = [7, 9, 11, 13, 15]  # number of tweets for each day in lookback window\r\n",
        "T = 5  # number or days in lookback window\r\n",
        "batch_size = 4\r\n",
        "gru_m_hidden_size = 64\r\n",
        "use_embedding_size = 512\r\n",
        "\r\n",
        "r = torch.zeros(batch_size, 0, gru_m_hidden_size)\r\n",
        "\r\n",
        "gru_m = GRU(use_embedding_size, gru_m_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "for t in range(T):\r\n",
        "\r\n",
        "    m = torch.rand(batch_size, K[0], use_embedding_size)\r\n",
        "\r\n",
        "    print('m.shape', m.shape)\r\n",
        "\r\n",
        "    h_m_0 = torch.randn(1, batch_size, gru_m_hidden_size)  # randomly initialized initial hidden state\r\n",
        "\r\n",
        "    h_m, h_m_n = gru_m(m, h_m_0)\r\n",
        "\r\n",
        "    print('h_m.shape', h_m.shape)\r\n",
        "    print('h_m_n.shape', h_m_n.shape)\r\n",
        "\r\n",
        "    attn_m_intermediate_size = 10\r\n",
        "\r\n",
        "    attn_m = LinearAttention(gru_m_hidden_size, attn_m_intermediate_size, 1)\r\n",
        "\r\n",
        "    r_t = attn_m(h_m)\r\n",
        "\r\n",
        "    print('r_t.shape', r_t.shape)\r\n",
        "\r\n",
        "    r = torch.cat((r, r_t), 1)\r\n",
        "\r\n",
        "    print('r.shape', r.shape)\r\n",
        "\r\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enAqzfkmdfeQ"
      },
      "source": [
        "gru_s_hidden_size = 64\r\n",
        "\r\n",
        "print('r.shape', r.shape)\r\n",
        "\r\n",
        "h_s_0 = torch.randn(1, batch_size, gru_s_hidden_size)  # randomly initialized initial hidden state\r\n",
        "gru_s = GRU(gru_m_hidden_size, gru_s_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "h_s, h_s_n = gru_s(r, h_s_0)\r\n",
        "\r\n",
        "print('h_s.shape', h_s_0.shape)\r\n",
        "print('h_s_n.shape', h_s_n.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXAAWKgffdf8"
      },
      "source": [
        "attn_s_intermediate_size = 10\r\n",
        "\r\n",
        "attn_s = LinearAttention(gru_s_hidden_size, attn_s_intermediate_size, 1)\r\n",
        "\r\n",
        "c = attn_s(h_s)\r\n",
        "\r\n",
        "print('c.shape', c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Jz8KgBl6e9"
      },
      "source": [
        "##Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzPwjITrmyf7"
      },
      "source": [
        "blend_size = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Zr5i8_l50p"
      },
      "source": [
        "blend = Blend(q.shape[2], c.shape[2], blend_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeSZ46RQm0MU"
      },
      "source": [
        "x = blend(q, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcwZyMyem98Q"
      },
      "source": [
        "print('x.shape', x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1odW9AqrnHsh"
      },
      "source": [
        "num_stocks = x.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyQFkoZRnPGI"
      },
      "source": [
        "x = x.view(x.shape[0], x.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrE9r47wnVTc"
      },
      "source": [
        "print('x.shape', x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wQptn1PhF4O"
      },
      "source": [
        "##GAT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYM_oYYiZ_MU"
      },
      "source": [
        "intermediate_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tqq-lLkfgyd"
      },
      "source": [
        "nhoods = [[0,1], [0,1,2], [1,2], [3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qG6e1Kcf_EV"
      },
      "source": [
        "shared_linear = SharedLinear(blend_size, intermediate_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrVwW5zQhJ3y"
      },
      "source": [
        "Wx = shared_linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BzfEWPBhkPr"
      },
      "source": [
        "print('Wx.shape', Wx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvWXAd_bkq3a"
      },
      "source": [
        "##MGAT 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pioV0X1TkrlQ"
      },
      "source": [
        "U = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PgSNyF_ozT_"
      },
      "source": [
        "elu = nn.ELU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Uu_ONMk_QD"
      },
      "source": [
        "sgat = SGAT(intermediate_size, 1)\r\n",
        "\r\n",
        "z = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "z = elu(z)\r\n",
        "\r\n",
        "for i in range(1, num_stocks):\r\n",
        "    z_i = sgat(Wx, nhoods, i)\r\n",
        "    z_i = elu(z_i)\r\n",
        "    z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "for u in range(1, U):\r\n",
        "    sgat = SGAT(intermediate_size, 1)\r\n",
        "\r\n",
        "    z_u = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "    z_u = elu(z_u)\r\n",
        "\r\n",
        "    for i in range(1, num_stocks):\r\n",
        "        z_u_i = sgat(Wx, nhoods, i)\r\n",
        "        z_u_i = elu(z_u_i)\r\n",
        "        z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "    \r\n",
        "    z = torch.cat((z, z_u), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVvTf8HSlr8H"
      },
      "source": [
        "print('z.shape', z.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPqJ4buPo8IK"
      },
      "source": [
        "##MGAT 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5pZ6tAou4N"
      },
      "source": [
        "U = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhQUWzqdpBPH"
      },
      "source": [
        "sigmoid = nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWhGU4dGpYJ6"
      },
      "source": [
        "new_intermediate_size = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOBKmXt2pRL0"
      },
      "source": [
        "shared_linear = SharedLinear(z.shape[1], new_intermediate_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbWJ366upbMn"
      },
      "source": [
        "Wx = shared_linear(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuGp_MB6piJt"
      },
      "source": [
        "print('Wx.shape', Wx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMM1wNxhpCe6"
      },
      "source": [
        "sgat = SGAT(new_intermediate_size, 1)\r\n",
        "\r\n",
        "z = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "z = sigmoid(z)\r\n",
        "\r\n",
        "for i in range(1, num_stocks):\r\n",
        "    z_i = sgat(Wx, nhoods, i)\r\n",
        "    z_i = sigmoid(z_i)\r\n",
        "    z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "for u in range(1, U):\r\n",
        "    sgat = SGAT(new_intermediate_size, 1)\r\n",
        "\r\n",
        "    z_u = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "    z_u = sigmoid(z_u)\r\n",
        "\r\n",
        "    for i in range(1, num_stocks):\r\n",
        "        z_u_i = sgat(Wx, nhoods, i)\r\n",
        "        z_u_i = sigmoid(z_u_i)\r\n",
        "        z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "    \r\n",
        "    z = torch.cat((z, z_u), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDpzJU-BpzTu"
      },
      "source": [
        "print('z.shape', z.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH8yQvp8p6CP"
      },
      "source": [
        "##Final Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhLolFHp_td"
      },
      "source": [
        "linear = nn.Linear(z.shape[1], 1, bias=True)\r\n",
        "sigmoid = nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNdZdAALqgMn"
      },
      "source": [
        "sigmoid(linear(z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIpPquknIZ23"
      },
      "source": [
        "print(sigmoid(linear(z)).shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}