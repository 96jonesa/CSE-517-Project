{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lVjNK8shFKOC"
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet \"tensorflow-hub>=0.7.0\"\n",
    "!pip3 install --quiet seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MSeY-MUQo2Ha"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kxiao36/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocknet_dataset_filepath = './stocknet-dataset-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:01<00:00, 61.28it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_prices_filepath = stocknet_dataset_filepath + '/price/preprocessed'\n",
    "preprocessed_tweets_filepath = stocknet_dataset_filepath + '/tweet/preprocessed'\n",
    "\n",
    "company_to_price_df = {}\n",
    "company_to_tweets = {}\n",
    "\n",
    "for filename in os.listdir(preprocessed_prices_filepath):\n",
    "    with open(preprocessed_prices_filepath + '/' + filename) as file:\n",
    "        company_name = filename.split('.')[0]\n",
    "        \n",
    "        # Not enough data for GMRE\n",
    "        if company_name == 'GMRE':\n",
    "            continue\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        df.columns = ['date', 'open', 'high', 'low', 'close', 'adjust_close', 'volume']\n",
    "        company_to_price_df[company_name] = df\n",
    "\n",
    "for filename in tqdm(os.listdir(preprocessed_tweets_filepath)):\n",
    "    company_name = filename.split('.')[0]\n",
    "    dates_to_tweets = {}\n",
    "    for tweet_filename in os.listdir(preprocessed_tweets_filepath + '/' + filename):\n",
    "        with open(preprocessed_tweets_filepath + '/' + filename + '/' + tweet_filename) as file:\n",
    "            list_of_tweets = []\n",
    "            for line in file:\n",
    "                tweet_json = json.loads(line)\n",
    "                list_of_tweets.append(tweet_json)\n",
    "            dates_to_tweets[tweet_filename] = list_of_tweets\n",
    "    company_to_tweets[company_name] = dates_to_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['rt', '$', 'tsla', 'hft', 'algos', 'triggered', 'buy', 'in', 'sigma-x', ',', 'crossfinder', ',', 'ats', ',', 'lx', '@', '08:28', ',', 'p', '/', 't', '245.00', 'quant', '$', 'msft', '$', 'fb', '$', 'gpro', '$', 'amzn', '$', 'goog', '$', 'aapl', '$', 'nflx', '$', 'qqq'], 'created_at': 'Fri Oct 02 12:29:15 +0000 2015', 'user_id_str': '242469235'}\n"
     ]
    }
   ],
   "source": [
    "#print(company_to_tweets.keys())\n",
    "#print(dates_to_tweets.keys())\n",
    "print(company_to_tweets['AAPL']['2015-10-02'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_to_tweets maps each company name to a dictionary of dates and list of tweets. Schema:\n",
    "\n",
    "{\n",
    "    company_name: \n",
    "    {\n",
    "        date: [list of tweets + metadata]\n",
    "        ...\n",
    "    }\n",
    "    ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27326,
     "status": "ok",
     "timestamp": 1612310937315,
     "user": {
      "displayName": "Kyle Xiao",
      "photoUrl": "",
      "userId": "04815696510931287234"
     },
     "user_tz": 480
    },
    "id": "Q8F4LNGFqOiq",
    "outputId": "240738bd-40be-4756-9dd3-667ab822145f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "  \n",
    "  for company in tqdm(company_to_tweets.keys()):\n",
    "    for date in company_to_tweets[company].keys():\n",
    "      messages = []\n",
    "      for j in range(len(company_to_tweets[company][date])):\n",
    "        messages.append(' '.join(company_to_tweets[company][date][j]['text']))\n",
    "      message_embeddings = session.run(embed(messages))\n",
    "      print(message_embeddings)\n",
    "      for k in range(len(company_to_tweets[company][date])):\n",
    "        company_to_tweets[company][date][k]['embedding'] = list(message_embeddings[k])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Universal Sentence Encoder",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/hub/blob/50bbebaa248cff13e82ddf0268ed1b149ef478f2/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb",
     "timestamp": 1612309725798
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
