{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lVjNK8shFKOC"
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet \"tensorflow-hub>=0.7.0\"\n",
    "!pip3 install --quiet seaborn\n",
    "# Install market calendar\n",
    "!pip3 install --quiet pandas-market-calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MSeY-MUQo2Ha"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pandas_market_calendars as mcal\n",
    "import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kxiao36/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocknet_dataset_filepath = './stocknet-dataset-master'\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2016-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "calendar = mcal.get_calendar('NYSE')\n",
    "def next_trading_day(start_day=None, SAFE_DELTA = 4):\n",
    "    \"\"\"Returns the next/previous trading date separated by a certain number of \n",
    "    trading days.\n",
    "    \"\"\"\n",
    "    if start_day is None:\n",
    "        start_day = datetime.datetime.utcnow().date()\n",
    "    if start_day in cache:\n",
    "        return cache[start_day]\n",
    "    start = pd.to_datetime(start_day)\n",
    "    end = start + np.timedelta64(SAFE_DELTA, 'D')\n",
    "    business_days = calendar.valid_days(start_date=start, end_date=end)\n",
    "    next_day = business_days[1].date()\n",
    "    next_day = next_day.strftime(\"%Y-%m-%d\")\n",
    "    cache[start_day] = next_day\n",
    "    return next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4793642b1ff9485e9bb7eefa9292cb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_prices_filepath = stocknet_dataset_filepath + '/price/preprocessed'\n",
    "preprocessed_tweets_filepath = stocknet_dataset_filepath + '/tweet/preprocessed'\n",
    "\n",
    "company_to_price_df = {}\n",
    "company_to_tweets = {}\n",
    "\n",
    "for filename in os.listdir(preprocessed_prices_filepath):\n",
    "    with open(preprocessed_prices_filepath + '/' + filename) as file:\n",
    "        company_name = filename.split('.')[0]\n",
    "        \n",
    "        # Not enough data for GMRE\n",
    "        if company_name == 'GMRE':\n",
    "            continue\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        df.columns = ['date', 'open', 'high', 'low', 'close', 'adjust_close', 'volume']\n",
    "        mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "        df = df.loc[mask]\n",
    "        company_to_price_df[company_name] = df.dropna()\n",
    "\n",
    "for filename in tqdm(os.listdir(preprocessed_tweets_filepath)):\n",
    "    company_name = filename.split('.')[0]\n",
    "    dates_to_tweets = {}\n",
    "    for tweet_filename in os.listdir(preprocessed_tweets_filepath + '/' + filename):\n",
    "        if tweet_filename < start_date or tweet_filename > end_date:\n",
    "            continue\n",
    "        with open(preprocessed_tweets_filepath + '/' + filename + '/' + tweet_filename) as file:\n",
    "            list_of_tweets = []\n",
    "            for line in file:\n",
    "                tweet_json = json.loads(line)\n",
    "                list_of_tweets.append(tweet_json)\n",
    "            date_idx = next_trading_day(tweet_filename)\n",
    "            if date_idx not in dates_to_tweets:\n",
    "                dates_to_tweets[date_idx] = list_of_tweets\n",
    "            else:\n",
    "                dates_to_tweets[date_idx] += list_of_tweets\n",
    "    company_to_tweets[company_name] = dates_to_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['apple', 'releases', 'ios', '9.0', '.', '2', 'with', 'bug', 'fixes', ',', 'performance', 'improvements', '-', 'URL', '-', '$', 'aapl', 'URL'], 'created_at': 'Thu Oct 01 09:57:36 +0000 2015', 'user_id_str': '229597766'}\n"
     ]
    }
   ],
   "source": [
    "#print(company_to_tweets.keys())\n",
    "#print(dates_to_tweets.keys())\n",
    "print(company_to_tweets['AAPL']['2015-10-02'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "def embed_useT(module):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})\n",
    "embed_fn = embed_useT(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fbfa7b55e04299a1e00babb1c3c9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "for company in tqdm(company_to_tweets.keys()):\n",
    "  for date in company_to_tweets[company].keys():\n",
    "    messages = []\n",
    "    for j in range(len(company_to_tweets[company][date])):\n",
    "      messages.append(' '.join(company_to_tweets[company][date][j]['text']))\n",
    "    message_embeddings = embed_fn(messages)\n",
    "    for k in range(len(company_to_tweets[company][date])):\n",
    "      company_to_tweets[company][date][k]['embedding'] = list(message_embeddings[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date mapping\n",
    "date_universe = set()\n",
    "for company in company_to_price_df.keys():\n",
    "    date_universe = date_universe.union(set(company_to_price_df[company].date))\n",
    "for company in company_to_tweets.keys():\n",
    "    date_universe = date_universe.union(set(company_to_tweets[company].keys()))\n",
    "date_universe = sorted(list(date_universe))\n",
    "index_to_date = {i-5:d for i,d in enumerate(date_universe)}\n",
    "date_to_index = {d:i-5 for i,d in enumerate(date_universe)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "505\n",
      "555\n"
     ]
    }
   ],
   "source": [
    "# Calculate dimensions for tensor\n",
    "n_stocks = len(company_to_tweets.keys())\n",
    "n_days = len(date_universe)\n",
    "max_tweets = 0\n",
    "for c,d in itertools.product(company_to_tweets.keys(), date_universe):\n",
    "    if d in company_to_tweets[c]:\n",
    "        max_tweets = max(max_tweets, len(company_to_tweets[c][d]))\n",
    "# Create index mapping for stocks alphabetically\n",
    "company_to_index = {c:i for i,c in enumerate(sorted(list(company_to_tweets.keys())))}\n",
    "# print dimensions\n",
    "print(n_stocks)\n",
    "print(n_days)\n",
    "print(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct tensors\n",
    "price_tensor = np.zeros((n_stocks, n_days-5, 6, 3))\n",
    "smi_tensor = np.zeros((n_stocks, n_days-5, 6, max_tweets, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    \"\"\"Price dataset\"\"\"\n",
    "\n",
    "    def __init__(self, company_to_price_df, company_to_tweets, date_universe, n_days, n_stocks, max_tweets):\n",
    "        # Initialize class members\n",
    "        self.n_stocks = n_stocks\n",
    "        self.n_days = n_days\n",
    "        self.max_tweets = max_tweets\n",
    "        company_to_index = {c:i for i,c in enumerate(sorted(list(company_to_tweets.keys())))}\n",
    "        date_to_index = {d:i for i,d in enumerate(date_universe)}\n",
    "        # Get price data tensor: n_stocks, n_days, 3\n",
    "        self.price_data = np.zeros((n_stocks, n_days, 3))\n",
    "        for company in company_to_price_df.keys():\n",
    "            df = company_to_price_df[company]\n",
    "            for index, row in df.iterrows():\n",
    "                d_index = date_to_index[row['date']]\n",
    "                c_index = company_to_index[company]\n",
    "                self.price_data[c_index, d_index, 0] = row['high']\n",
    "                self.price_data[c_index, d_index, 1] = row['low']\n",
    "                self.price_data[c_index, d_index, 2] = row['adjust_close']\n",
    "        # Get smi data tensor\n",
    "        self.smi_data = np.zeros((n_stocks, n_days, max_tweets, 512))\n",
    "        self.tweet_counts = np.zeros((n_stocks, n_days))\n",
    "        for company in company_to_tweets.keys():\n",
    "            dates = sorted(list(company_to_tweets[company].keys()))\n",
    "            for date in dates:\n",
    "                n_tweets = len(company_to_tweets[company][date])\n",
    "                tweets = [company_to_tweets[company][date][k]['embedding'] for k in range(n_tweets)]\n",
    "                c_index = company_to_index[company]\n",
    "                d_index = date_to_index[date]\n",
    "                self.tweet_counts[c_index, d_index] = n_tweets\n",
    "                for i,embedding in enumerate(tweets):\n",
    "                    #stocks, day, lags, tweet, embedding\n",
    "                    self.smi_data[c_index, d_index, i, :] = embedding[:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_days-5\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        gets a price tensor of shape (n_stocks, 6, 3)\n",
    "        gets a smi tensor of shape (n_stocks, 6, K, 512)\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        #price_output = np.zeros((self.n_stocks, 6, 3))\n",
    "        price_output = self.price_data[:, idx:idx+6, :]\n",
    "        \n",
    "        #smi_output = np.zeros((self.n_stocks, 6, self.max_tweets, 512))\n",
    "        smi_output = self.smi_data[:, idx:idx+6, :, :]\n",
    "        \n",
    "        tweet_count = self.tweet_counts[:, idx:idx+6]\n",
    "        \n",
    "        # construct output\n",
    "        output = {'price': price_output, 'smi': smi_output, 'n_tweets': tweet_count}\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dataset = StockDataset(company_to_price_df, company_to_tweets, date_universe, n_days, n_stocks, max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(price_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i_batch, sample_batched in enumerate(dataloader):\\n    print(i_batch)\\n    print(sample_batched)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch)\n",
    "    print(sample_batched)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Universal Sentence Encoder",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/hub/blob/50bbebaa248cff13e82ddf0268ed1b149ef478f2/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb",
     "timestamp": 1612309725798
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
