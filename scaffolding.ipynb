{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scaffolding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGzyD31Zs31U2Nntg+JQGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/96jonesa/CSE-517-Project/blob/main/scaffolding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUxhN7LDSGGz"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bn0eEsGSB3N"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IchYXapSJjH"
      },
      "source": [
        "#GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-YF6GyHzwE2"
      },
      "source": [
        "##GRU\r\n",
        "This is just a wrapper around nn.GRU for the sake of consistency. Used in the Price Encoder, day-level SMI Encoder, and temporal SMI Encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OVZXsnSJH3"
      },
      "source": [
        "class GRU(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, batch_first=False):\r\n",
        "        super(GRU, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.batch_first = batch_first\r\n",
        "\r\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=self.batch_first)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        output, hn = self.gru(input)\r\n",
        "        return output, hn"
      ],
      "execution_count": 478,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRniLDIGSf5Y"
      },
      "source": [
        "#Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDM1G23a0J4V"
      },
      "source": [
        "##LinearAttention\r\n",
        "The attention mechanism used in Feng et. al. Used in the Price Encoder, day-level SMI Encoder, and temporal SMI Encoder. Given input $h$, returns\r\n",
        "$q_t = \\sum_{i=t-T}^T \\beta_i h_i$ where $\\beta_i = \\dfrac{\\exp\\left( u^T \\tanh \\left( W h_i + b \\right) \\right)}{\\sum_{k=t-T}^t \\exp\\left( u^T \\tanh \\left( W h_k + b \\right) \\right)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDJ054vAquLa"
      },
      "source": [
        "# attention weights are softmax(u^T tanh(W input + b)) where W is learned parameter matrix, u is a learned parameter vector, and b is a learned offset\r\n",
        "\r\n",
        "class LinearAttention(nn.Module):\r\n",
        "    def __init__(self, input_size, intermediate_size, weights_size):\r\n",
        "        super(LinearAttention, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.intermediate_size = intermediate_size\r\n",
        "        self.weights_size = weights_size\r\n",
        "\r\n",
        "        self.linear_1 = nn.Linear(self.input_size, self.intermediate_size, bias=True)\r\n",
        "        self.linear_2 = nn.Linear(self.intermediate_size, self.weights_size, bias=False)\r\n",
        "        self.tanh = nn.Tanh()\r\n",
        "        self.softmax = nn.Softmax(dim=2)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        intermediate = self.tanh(self.linear_1(input))\r\n",
        "        attention_weights = self.softmax(self.linear_2(intermediate))\r\n",
        "        attention_weights = attention_weights.permute(0, 2, 1)\r\n",
        "        output_features = torch.bmm(attention_weights, input)\r\n",
        "\r\n",
        "        return output_features"
      ],
      "execution_count": 479,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qkvwOlPW3kt"
      },
      "source": [
        "#Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AMUuaLR06Ph"
      },
      "source": [
        "##Blend\r\n",
        "Applies a learned bilinear transformation to the left and right vectors, then inputs the result to a ReLU non-linearity. Used to obtain Multi-Modal Encodings from Price Encodings and temporal SMI Encodings. Given Price Encodings $q_t$ and temporal SMI Encodings $c_t$, returns\r\n",
        "$x_t = \\mathcal{B} \\left( c_t, q_t \\right) = \\text{ReLU} \\left( q_t^T W c_t + b \\right)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmdq6ozMV1u8"
      },
      "source": [
        "# output is ReLU(left^T W right + b) where W is a learned paramater matrix\r\n",
        "# and b is a learned bias\r\n",
        "\r\n",
        "class Blend(nn.Module):\r\n",
        "    def __init__(self, left_size, right_size, output_size):\r\n",
        "        super(Blend, self).__init__()\r\n",
        "        self.left_size = left_size\r\n",
        "        self.right_size = right_size\r\n",
        "        self.output_size = output_size\r\n",
        "\r\n",
        "        self.bilinear = nn.Bilinear(self.left_size, self.right_size, output_size, bias=True)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "    \r\n",
        "    def forward(self, left, right):\r\n",
        "        output = self.relu(self.bilinear(left, right))\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zknLj7UautA"
      },
      "source": [
        "#Single-Headed Graph Attention Network (SGAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MQfBWhE1XR6"
      },
      "source": [
        "##SharedLinear\r\n",
        "This is just a wrapper around nn.Linear for the sake of consistency. Used to apply a shared linear transformation to all inputs of an SGAT layer. Under current implementation, this should be applied before passing inputs to SGAT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DYXTg2piK_J"
      },
      "source": [
        "# need shared learned parameter matrix W to multiply against each input vector\r\n",
        "\r\n",
        "class SharedLinear(nn.Module):\r\n",
        "    def __init__(self, input_size, output_size):\r\n",
        "        super(SharedLinear, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.output_size = output_size\r\n",
        "        \r\n",
        "        self.linear = nn.Linear(input_size, output_size, bias=False)\r\n",
        "    \r\n",
        "    def forward(self, input):\r\n",
        "        output = self.linear(input)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu7zaUMD10iy"
      },
      "source": [
        "##SGAT\r\n",
        "A single-headed GAT layer. A shared linear transform $W$ is applied to all the nodes *before* passing them as input to this module (by passing them as input to a SharedLinear layer), then a shared self-attention mechanism is applied to each node $i$ in its immediate neighborhood $\\mathcal{N}_i$. For each node $j\\in \\mathcal{N}_i$, normalized attention coefficients $\\alpha_{i,j}$ are computed to represent the importance of the relations between stocks $i$ and $j$. That is,\r\n",
        "$\\alpha_{i,j} = \\dfrac{\\exp ( \\text{LeakyReLU} ( a_w^T [ W x_i \r\n",
        "\\oplus W x_j ] ) )}{\\sum_{k\\in \\mathcal{N}_i} \\exp ( \\text{LeakyReLU} ( a_w^T [ W x_i \\oplus W x_k ] ) )}$\r\n",
        "where $\\oplus$ denotes concatenation and $a_w$ is a learned parameter matrix. An updated feature vector $z_i$ for the $i$-th stock is computed by applying these attention weights to the linearly transformed multi-modal feature vectors of all of the stocks in $\\mathcal{N}_i$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0uaOH5UW2cc"
      },
      "source": [
        "# merge code with MGAT code to form general case GAT code\r\n",
        "\r\n",
        "class SGAT(nn.Module):\r\n",
        "    def __init__(self, input_size, weights_size, leakyrelu_slope=0.01):\r\n",
        "        super(SGAT, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.weights_size = weights_size\r\n",
        "        self.leakyrelu_slope = leakyrelu_slope\r\n",
        "        \r\n",
        "        self.linear = nn.Linear(2 * input_size, weights_size, bias=False)\r\n",
        "        self.leakyrelu = nn.LeakyReLU(self.leakyrelu_slope)\r\n",
        "        self.softmax = nn.Softmax(dim=1)\r\n",
        "\r\n",
        "    def forward(self, input, neighborhoods, index):\r\n",
        "        stock = input[index]\r\n",
        "        neighborhood = neighborhoods[index]\r\n",
        "        stack_stock = stock.expand(len(neighborhood), stock.shape[0])\r\n",
        "        stack_neighbors = input[neighborhood]\r\n",
        "        cat_stock = torch.cat((stack_stock, stack_neighbors), dim=1)\r\n",
        "        attention_weights = self.softmax(self.leakyrelu(self.linear(cat_stock)))  # check this\r\n",
        "        output_features = torch.mm(attention_weights.T, stack_neighbors)  # check this\r\n",
        "\r\n",
        "        return output_features"
      ],
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km8lDrqXkPIR"
      },
      "source": [
        "#MAN-SF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdXk_nhNs8Jm"
      },
      "source": [
        "class MANSF(nn.Module):\r\n",
        "    def __init__(self, T, num_stocks, gru_hidden_size, attn_inter_size, use_embed_size,\r\n",
        "                 blend_size, gat_1_inter_size, gat_2_inter_size, leakyrelu_slope, elu_alpha, U):\r\n",
        "        super(MANSF, self).__init__()\r\n",
        "        self.T = T\r\n",
        "        self.num_stocks = num_stocks\r\n",
        "        self.gru_hidden_size = gru_hidden_size\r\n",
        "        self.attn_inter_size = attn_inter_size\r\n",
        "        self.K = K\r\n",
        "        self.use_embed_size = use_embed_size\r\n",
        "        self.blend_size = blend_size\r\n",
        "        self.gat_1_inter_size = gat_1_inter_size\r\n",
        "        self.gat_2_inter_size = gat_2_inter_size\r\n",
        "        self.leakyrelu_slope = leakyrelu_slope\r\n",
        "        self.elu_alpha = elu_alpha\r\n",
        "        self.U = U\r\n",
        "\r\n",
        "        self.gru_p = GRU(3, gru_hidden_size, batch_first=True)\r\n",
        "        self.gru_m = GRU(use_embed_size, gru_hidden_size, batch_first=True)\r\n",
        "        self.gru_s = GRU(gru_hidden_size, gru_hidden_size, batch_first=True)\r\n",
        "        self.attn_p = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.attn_m = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.attn_s = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.blend = Blend(use_embed_size, use_embed_size, blend_size)\r\n",
        "        self.shared_linears_1 = []\r\n",
        "        for u in range(U):\r\n",
        "            self.shared_linears_1.append(SharedLinear(blend_size, gat_1_inter_size))\r\n",
        "        self.shared_linears_2 = []\r\n",
        "        for u in range(U):\r\n",
        "            self.shared_linears_2.append(SharedLinear(U * gat_1_inter_size, gat_2_inter_size))\r\n",
        "        self.mgat_1 = []\r\n",
        "        for u in range(U):\r\n",
        "            self.mgat_1.append(SGAT(gat_1_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "        self.mgat_2 = []\r\n",
        "        for u in range(U):\r\n",
        "            self.mgat_2.append(SGAT(gat_2_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        self.elu = nn.ELU(elu_alpha)\r\n",
        "        self.final_linear = nn.Linear(U * gat_2_inter_size, 1, bias=True)\r\n",
        "\r\n",
        "    # p is price data tensor of shape (num_stocks, T, 3), for the day under consideration\r\n",
        "    #\r\n",
        "    # m is smi data list of tensors of shape (num_stocks, K, use_embed_size) of length T,\r\n",
        "    #       where K is the number of tweets for the given stock on the day under consideration\r\n",
        "    #\r\n",
        "    # neighorhoods is a list of adjacency lists, where each stock is indexed with the same\r\n",
        "    #       indices they have in p and m\r\n",
        "    #\r\n",
        "    # TODO: tensorize day-level smi\r\n",
        "    # TODO: tensorize sgat \r\n",
        "    def forward(self, p, m, neighborhoods):\r\n",
        "        ## price encoding\r\n",
        "        h_p, _ = self.gru_p(p)\r\n",
        "        q = self.attn_p(h_p)\r\n",
        "\r\n",
        "        ## smi encoding (day level)\r\n",
        "        r = torch.zeros(self.num_stocks, 0, self.gru_hidden_size)\r\n",
        "        for t in range(self.T):\r\n",
        "            h_m, _ = self.gru_m(m[t])\r\n",
        "            r_t = self.attn_m(h_m)\r\n",
        "            r = torch.cat((r, r_t), 1)\r\n",
        "\r\n",
        "        ## smi encoding (aggregate)\r\n",
        "        h_s, _ = self.gru_s(r)\r\n",
        "        c = self.attn_s(h_s)\r\n",
        "\r\n",
        "        ## blending\r\n",
        "        x = self.blend(q, c)\r\n",
        "\r\n",
        "        ## reshaping (eliminating superfluous dimension)\r\n",
        "        x = x.view(x.shape[0], x.shape[2])\r\n",
        "\r\n",
        "        ## first gat layer\r\n",
        "        #  first head\r\n",
        "        shared_linear = self.shared_linears_1[0]\r\n",
        "        Wx = shared_linear(x)\r\n",
        "        sgat = self.mgat_1[0]\r\n",
        "        z = sgat(Wx, neighborhoods, 0)\r\n",
        "        z = self.elu(z)\r\n",
        "\r\n",
        "        for i in range(1, self.num_stocks):\r\n",
        "            z_i = sgat(Wx, neighborhoods, i)\r\n",
        "            z_i = self.elu(z_i)\r\n",
        "            z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "        #  remaining heads\r\n",
        "        for u in range(1, self.U):\r\n",
        "            shared_linear = self.shared_linears_1[u]\r\n",
        "            Wx = shared_linear(x)\r\n",
        "            sgat = self.mgat_1[u]\r\n",
        "            z_u = sgat(Wx, neighborhoods, 0)\r\n",
        "            z_u = self.elu(z_u)\r\n",
        "\r\n",
        "            for i in range(1, self.num_stocks):\r\n",
        "                z_u_i = sgat(Wx, neighborhoods, i)\r\n",
        "                z_u_i = self.elu(z_u_i)\r\n",
        "                z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "            \r\n",
        "            z = torch.cat((z, z_u), 1)\r\n",
        "        \r\n",
        "        ## second gat layer\r\n",
        "        #  first head\r\n",
        "        shared_linear = self.shared_linears_2[0]\r\n",
        "        Wx = shared_linear(z)\r\n",
        "        sgat = self.mgat_2[0]\r\n",
        "        new_z = sgat(Wx, neighborhoods, 0)\r\n",
        "        new_z = self.sigmoid(new_z)\r\n",
        "\r\n",
        "        for i in range(1, self.num_stocks):\r\n",
        "            new_z_i = sgat(Wx, neighborhoods, i)\r\n",
        "            new_z_i = self.sigmoid(new_z_i)\r\n",
        "            new_z = torch.cat((new_z, new_z_i), 0)\r\n",
        "\r\n",
        "        #  remaining heads\r\n",
        "        for u in range(1, self.U):\r\n",
        "            shared_linear = self.shared_linears_2[u]\r\n",
        "            Wx = shared_linear(z)\r\n",
        "            sgat = self.mgat_2[u]\r\n",
        "            new_z_u = sgat(Wx, neighborhoods, 0)\r\n",
        "            new_z_u = self.sigmoid(new_z_u)\r\n",
        "\r\n",
        "            for i in range(1, self.num_stocks):\r\n",
        "                new_z_u_i = sgat(Wx, neighborhoods, i)\r\n",
        "                new_z_u_i = self.sigmoid(new_z_u_i)\r\n",
        "                new_z_u = torch.cat((new_z_u, new_z_u_i), 0)\r\n",
        "            \r\n",
        "            new_z = torch.cat((new_z, new_z_u), 1)\r\n",
        "        \r\n",
        "        ## final layer\r\n",
        "        y = self.sigmoid(self.final_linear(new_z))\r\n",
        "\r\n",
        "        ## return result\r\n",
        "        return y"
      ],
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGJlWH03F6Vm"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOrNDPkGF7Lx"
      },
      "source": [
        "p = torch.tensor([[[1.5, 1.8, 1.2], [1.7, 1.9, 1.3]], [[0.8, 0.9, 0.6], [0.6, 0.7, 0.4]]])"
      ],
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5RpydUnHCY_",
        "outputId": "6216264c-1af0-4003-ff2e-14a16c734a68"
      },
      "source": [
        "print(p.shape)"
      ],
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajvv409nHEQW"
      },
      "source": [
        "m = [torch.zeros(2,1,64),torch.zeros(2,1,64)]"
      ],
      "execution_count": 486,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsW9psWTH5Q0",
        "outputId": "173e7167-0a47-4638-a792-f99854dcc4f7"
      },
      "source": [
        "print(m[0].shape)"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm8MhsktIEmL"
      },
      "source": [
        "neighborhoods = [[0,1],[0,1]]"
      ],
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHhPTGwtITTJ"
      },
      "source": [
        "Y = torch.tensor([[1.0],[0.0]])"
      ],
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAxznczuI1Mk",
        "outputId": "66978c55-3d77-4e34-c0c1-7753592ffa48"
      },
      "source": [
        "print(Y.shape)"
      ],
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d71ifgz-I2HP"
      },
      "source": [
        "mansf = MANSF(T=2,\r\n",
        "              num_stocks=2,\r\n",
        "              gru_hidden_size=64,\r\n",
        "              attn_inter_size=32,\r\n",
        "              use_embed_size=64,\r\n",
        "              blend_size=32,\r\n",
        "              gat_1_inter_size=32,\r\n",
        "              gat_2_inter_size=32,\r\n",
        "              leakyrelu_slope=0.01,\r\n",
        "              elu_alpha=1.0,\r\n",
        "              U=8)"
      ],
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPqWqHO3JSes"
      },
      "source": [
        "y = mansf(p, m, neighborhoods)"
      ],
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZvi0n_YKF0x",
        "outputId": "78ba6004-2d59-4516-a066-7aa5a766da6b"
      },
      "source": [
        "print(y)  # initial predictions without training"
      ],
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5550],\n",
            "        [0.5550]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln1XgFXjKXL2",
        "outputId": "fa633565-ba4f-4246-d17e-3913a450c4b5"
      },
      "source": [
        "optimizer = optim.Adam(mansf.parameters())\r\n",
        "loss_fn = nn.BCELoss()\r\n",
        "\r\n",
        "for epoch in range(100):\r\n",
        "    mansf.train()\r\n",
        "    y = mansf(p, m, neighborhoods)\r\n",
        "    loss = loss_fn(y.view(-1), Y.view(-1))\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    print(y[0].item(), y[1].item())"
      ],
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5549602508544922 0.5549602508544922\n",
            "0.5151888132095337 0.5151888132095337\n",
            "0.48320329189300537 0.48320329189300537\n",
            "0.46835362911224365 0.46835362911224365\n",
            "0.4686594307422638 0.4686594307422638\n",
            "0.47756603360176086 0.47756603360176086\n",
            "0.4906877875328064 0.4906877875328064\n",
            "0.5044553875923157 0.5044553875923157\n",
            "0.5153114199638367 0.5153114199638367\n",
            "0.5208621025085449 0.5208621025085449\n",
            "0.5207500457763672 0.5207500457763672\n",
            "0.5158942937850952 0.5158942937850952\n",
            "0.5081143379211426 0.5081143379211426\n",
            "0.49927276372909546 0.49927276372909546\n",
            "0.49151119589805603 0.49151119589805603\n",
            "0.4864804446697235 0.4864804446697235\n",
            "0.48496222496032715 0.48496222496032715\n",
            "0.4868171811103821 0.4868171811103821\n",
            "0.4912576675415039 0.4912576675415039\n",
            "0.4971138834953308 0.4971138834953308\n",
            "0.5030441284179688 0.5030441284179688\n",
            "0.5076873302459717 0.5076873302459717\n",
            "0.5102414488792419 0.5102414488792419\n",
            "0.5103527307510376 0.5103527307510376\n",
            "0.5082301497459412 0.5082301497459412\n",
            "0.5045348405838013 0.5045348405838013\n",
            "0.5001970529556274 0.5001970529556274\n",
            "0.4962122440338135 0.4962122440338135\n",
            "0.49342867732048035 0.49342867732048035\n",
            "0.49236318469047546 0.49236318469047546\n",
            "0.4931049048900604 0.4931049048900604\n",
            "0.4953339397907257 0.4953339397907257\n",
            "0.49842569231987 0.49842569231987\n",
            "0.5016046166419983 0.5016046166419983\n",
            "0.5041236281394958 0.5041236281394958\n",
            "0.5054389834403992 0.5054389834403992\n",
            "0.5053348541259766 0.5053348541259766\n",
            "0.5039547085762024 0.5039547085762024\n",
            "0.5017389059066772 0.5017389059066772\n",
            "0.49929776787757874 0.49929776787757874\n",
            "0.49725255370140076 0.49725255370140076\n",
            "0.49608108401298523 0.49608108401298523\n",
            "0.4960058629512787 0.4960058629512787\n",
            "0.49695509672164917 0.49695509672164917\n",
            "0.4986017346382141 0.4986017346382141\n",
            "0.50046306848526 0.50046306848526\n",
            "0.5020339488983154 0.5020339488983154\n",
            "0.5029212832450867 0.5029212832450867\n",
            "0.5029435753822327 0.5029435753822327\n",
            "0.5021668672561646 0.5021668672561646\n",
            "0.5008697509765625 0.5008697509765625\n",
            "0.4994521141052246 0.4994521141052246\n",
            "0.49831709265708923 0.49831709265708923\n",
            "0.49775823950767517 0.49775823950767517\n",
            "0.49788445234298706 0.49788445234298706\n",
            "0.49860236048698425 0.49860236048698425\n",
            "0.49965643882751465 0.49965643882751465\n",
            "0.5007132887840271 0.5007132887840271\n",
            "0.5014638900756836 0.5014638900756836\n",
            "0.501712441444397 0.501712441444397\n",
            "0.5014277100563049 0.5014277100563049\n",
            "0.5007405877113342 0.5007405877113342\n",
            "0.49989309906959534 0.49989309906959534\n",
            "0.4991569519042969 0.4991569519042969\n",
            "0.49874839186668396 0.49874839186668396\n",
            "0.4987654387950897 0.4987654387950897\n",
            "0.4991660416126251 0.4991660416126251\n",
            "0.4997916519641876 0.4997916519641876\n",
            "0.5004250407218933 0.5004250407218933\n",
            "0.5008637309074402 0.5008637309074402\n",
            "0.500983476638794 0.500983476638794\n",
            "0.5007733702659607 0.5007733702659607\n",
            "0.5003305077552795 0.5003305077552795\n",
            "0.4998205304145813 0.4998205304145813\n",
            "0.4994177520275116 0.4994177520275116\n",
            "0.4992467761039734 0.4992467761039734\n",
            "0.49934425950050354 0.49934425950050354\n",
            "0.49965405464172363 0.49965405464172363\n",
            "0.500052273273468 0.500052273273468\n",
            "0.5003951787948608 0.5003951787948608\n",
            "0.500569760799408 0.500569760799408\n",
            "0.5005303025245667 0.5005303025245667\n",
            "0.5003095865249634 0.5003095865249634\n",
            "0.500001072883606 0.500001072883606\n",
            "0.4997212588787079 0.4997212588787079\n",
            "0.4995669424533844 0.4995669424533844\n",
            "0.4995819926261902 0.4995819926261902\n",
            "0.4997459650039673 0.4997459650039673\n",
            "0.49998629093170166 0.49998629093170166\n",
            "0.500208854675293 0.500208854675293\n",
            "0.5003339052200317 0.5003339052200317\n",
            "0.5003241300582886 0.5003241300582886\n",
            "0.5001952052116394 0.5001952052116394\n",
            "0.500005841255188 0.500005841255188\n",
            "0.4998323321342468 0.4998323321342468\n",
            "0.4997384250164032 0.4997384250164032\n",
            "0.499752402305603 0.499752402305603\n",
            "0.49985936284065247 0.49985936284065247\n",
            "0.5000098943710327 0.5000098943710327\n",
            "0.5001423358917236 0.5001423358917236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laFsXLtlL6Ai",
        "outputId": "d3890fec-9b5b-42e7-8e07-7f653f9e4972"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5002],\n",
            "        [0.5002]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxCeTPkshTiD"
      },
      "source": [
        "#Sandbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXK3JLoK4SgP"
      },
      "source": [
        "##Price Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrA5qKZwhTK7",
        "outputId": "920a8491-9fb0-43a0-9585-44bf94e2ce25"
      },
      "source": [
        "T = 5  # number of days in lookback window\r\n",
        "batch_size = 4\r\n",
        "gru_p_hidden_size = 64\r\n",
        "\r\n",
        "p = torch.rand(batch_size, T, 3)  # p_i = [p_i^c, p_i^h, p_i^l], not bothering to normalize for shape tests\r\n",
        "\r\n",
        "print('p.shape', p.shape)\r\n",
        "\r\n",
        "h_p_0 = torch.randn(1, batch_size, gru_p_hidden_size)  # randomly initialized initial hidden state\r\n",
        "gru_p = GRU(3, gru_p_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "h_p, h_p_n = gru_p(p, h_p_0)\r\n",
        "\r\n",
        "print('h_p.shape', h_p.shape)\r\n",
        "print('h_p_n.shape', h_p_n.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p.shape torch.Size([4, 5, 3])\n",
            "h_p.shape torch.Size([4, 5, 64])\n",
            "h_p_n.shape torch.Size([1, 4, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXkpe2m1oE7p",
        "outputId": "16005cad-3bf5-4771-8d76-254b2189632d"
      },
      "source": [
        "attn_p_intermediate_size = 10\r\n",
        "\r\n",
        "attn_p = LinearAttention(gru_p_hidden_size, attn_p_intermediate_size, 1)\r\n",
        "\r\n",
        "q = attn_p(h_p)\r\n",
        "\r\n",
        "print('q.shape', q.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "q.shape torch.Size([4, 1, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfVX_mwE4Upm"
      },
      "source": [
        "##SMI Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpbYUa13FP2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b31d4e-5c66-45c1-abd3-a02ca59e8005"
      },
      "source": [
        "K = [7, 9, 11, 13, 15]  # number of tweets for each day in lookback window\r\n",
        "T = 5  # number or days in lookback window\r\n",
        "batch_size = 4\r\n",
        "gru_m_hidden_size = 64\r\n",
        "use_embedding_size = 512\r\n",
        "\r\n",
        "r = torch.zeros(batch_size, 0, gru_m_hidden_size)\r\n",
        "\r\n",
        "gru_m = GRU(use_embedding_size, gru_m_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "for t in range(T):\r\n",
        "\r\n",
        "    m = torch.rand(batch_size, K[0], use_embedding_size)\r\n",
        "\r\n",
        "    print('m.shape', m.shape)\r\n",
        "\r\n",
        "    h_m_0 = torch.randn(1, batch_size, gru_m_hidden_size)  # randomly initialized initial hidden state\r\n",
        "\r\n",
        "    h_m, h_m_n = gru_m(m, h_m_0)\r\n",
        "\r\n",
        "    print('h_m.shape', h_m.shape)\r\n",
        "    print('h_m_n.shape', h_m_n.shape)\r\n",
        "\r\n",
        "    attn_m_intermediate_size = 10\r\n",
        "\r\n",
        "    attn_m = LinearAttention(gru_m_hidden_size, attn_m_intermediate_size, 1)\r\n",
        "\r\n",
        "    r_t = attn_m(h_m)\r\n",
        "\r\n",
        "    print('r_t.shape', r_t.shape)\r\n",
        "\r\n",
        "    r = torch.cat((r, r_t), 1)\r\n",
        "\r\n",
        "    print('r.shape', r.shape)\r\n",
        "\r\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m.shape torch.Size([4, 7, 512])\n",
            "h_m.shape torch.Size([4, 7, 64])\n",
            "h_m_n.shape torch.Size([1, 4, 64])\n",
            "r_t.shape torch.Size([4, 1, 64])\n",
            "r.shape torch.Size([4, 1, 64])\n",
            "\n",
            "m.shape torch.Size([4, 7, 512])\n",
            "h_m.shape torch.Size([4, 7, 64])\n",
            "h_m_n.shape torch.Size([1, 4, 64])\n",
            "r_t.shape torch.Size([4, 1, 64])\n",
            "r.shape torch.Size([4, 2, 64])\n",
            "\n",
            "m.shape torch.Size([4, 7, 512])\n",
            "h_m.shape torch.Size([4, 7, 64])\n",
            "h_m_n.shape torch.Size([1, 4, 64])\n",
            "r_t.shape torch.Size([4, 1, 64])\n",
            "r.shape torch.Size([4, 3, 64])\n",
            "\n",
            "m.shape torch.Size([4, 7, 512])\n",
            "h_m.shape torch.Size([4, 7, 64])\n",
            "h_m_n.shape torch.Size([1, 4, 64])\n",
            "r_t.shape torch.Size([4, 1, 64])\n",
            "r.shape torch.Size([4, 4, 64])\n",
            "\n",
            "m.shape torch.Size([4, 7, 512])\n",
            "h_m.shape torch.Size([4, 7, 64])\n",
            "h_m_n.shape torch.Size([1, 4, 64])\n",
            "r_t.shape torch.Size([4, 1, 64])\n",
            "r.shape torch.Size([4, 5, 64])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enAqzfkmdfeQ",
        "outputId": "ec0279a1-8a0e-4b8b-fa20-378102859d7d"
      },
      "source": [
        "gru_s_hidden_size = 64\r\n",
        "\r\n",
        "print('r.shape', r.shape)\r\n",
        "\r\n",
        "h_s_0 = torch.randn(1, batch_size, gru_s_hidden_size)  # randomly initialized initial hidden state\r\n",
        "gru_s = GRU(gru_m_hidden_size, gru_s_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "h_s, h_s_n = gru_s(r, h_s_0)\r\n",
        "\r\n",
        "print('h_s.shape', h_s_0.shape)\r\n",
        "print('h_s_n.shape', h_s_n.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r.shape torch.Size([4, 5, 64])\n",
            "h_s.shape torch.Size([1, 4, 64])\n",
            "h_s_n.shape torch.Size([1, 4, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXAAWKgffdf8",
        "outputId": "cca067d9-9f6a-445d-c243-7e9a7e2f8ca9"
      },
      "source": [
        "attn_s_intermediate_size = 10\r\n",
        "\r\n",
        "attn_s = LinearAttention(gru_s_hidden_size, attn_s_intermediate_size, 1)\r\n",
        "\r\n",
        "c = attn_s(h_s)\r\n",
        "\r\n",
        "print('c.shape', c.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c.shape torch.Size([4, 1, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Jz8KgBl6e9"
      },
      "source": [
        "##Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzPwjITrmyf7"
      },
      "source": [
        "blend_size = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Zr5i8_l50p"
      },
      "source": [
        "blend = Blend(q.shape[2], c.shape[2], blend_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeSZ46RQm0MU"
      },
      "source": [
        "x = blend(q, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcwZyMyem98Q",
        "outputId": "b7b80061-3730-4325-a55e-ed7b2814f36a"
      },
      "source": [
        "print('x.shape', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape torch.Size([4, 1, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1odW9AqrnHsh"
      },
      "source": [
        "num_stocks = x.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyQFkoZRnPGI"
      },
      "source": [
        "x = x.view(x.shape[0], x.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrE9r47wnVTc",
        "outputId": "249f0175-2dbc-4cab-ff89-236553d124a1"
      },
      "source": [
        "print('x.shape', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape torch.Size([4, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wQptn1PhF4O"
      },
      "source": [
        "##GAT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYM_oYYiZ_MU"
      },
      "source": [
        "intermediate_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tqq-lLkfgyd"
      },
      "source": [
        "nhoods = [[0,1], [0,1,2], [1,2], [3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qG6e1Kcf_EV"
      },
      "source": [
        "shared_linear = SharedLinear(blend_size, intermediate_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrVwW5zQhJ3y"
      },
      "source": [
        "Wx = shared_linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BzfEWPBhkPr",
        "outputId": "6bbfe892-edb8-456b-8a6e-4719330fb58c"
      },
      "source": [
        "print('Wx.shape', Wx.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvWXAd_bkq3a"
      },
      "source": [
        "##MGAT 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pioV0X1TkrlQ"
      },
      "source": [
        "U = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PgSNyF_ozT_"
      },
      "source": [
        "elu = nn.ELU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Uu_ONMk_QD"
      },
      "source": [
        "sgat = SGAT(intermediate_size, 1)\r\n",
        "\r\n",
        "z = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "z = elu(z)\r\n",
        "\r\n",
        "for i in range(1, num_stocks):\r\n",
        "    z_i = sgat(Wx, nhoods, i)\r\n",
        "    z_i = elu(z_i)\r\n",
        "    z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "for u in range(1, U):\r\n",
        "    sgat = SGAT(intermediate_size, 1)\r\n",
        "\r\n",
        "    z_u = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "    z_u = elu(z_u)\r\n",
        "\r\n",
        "    for i in range(1, num_stocks):\r\n",
        "        z_u_i = sgat(Wx, nhoods, i)\r\n",
        "        z_u_i = elu(z_u_i)\r\n",
        "        z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "    \r\n",
        "    z = torch.cat((z, z_u), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVvTf8HSlr8H",
        "outputId": "4aac3cc6-9f9c-414b-ea3e-edd243611d2e"
      },
      "source": [
        "print('z.shape', z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z.shape torch.Size([4, 40])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPqJ4buPo8IK"
      },
      "source": [
        "##MGAT 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5pZ6tAou4N"
      },
      "source": [
        "U = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhQUWzqdpBPH"
      },
      "source": [
        "sigmoid = nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWhGU4dGpYJ6"
      },
      "source": [
        "new_intermediate_size = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOBKmXt2pRL0"
      },
      "source": [
        "shared_linear = SharedLinear(z.shape[1], new_intermediate_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbWJ366upbMn"
      },
      "source": [
        "Wx = shared_linear(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuGp_MB6piJt",
        "outputId": "91c163f7-e33e-489e-c95f-541b32c07a04"
      },
      "source": [
        "print('Wx.shape', Wx.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wx.shape torch.Size([4, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMM1wNxhpCe6"
      },
      "source": [
        "sgat = SGAT(new_intermediate_size, 1)\r\n",
        "\r\n",
        "z = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "z = sigmoid(z)\r\n",
        "\r\n",
        "for i in range(1, num_stocks):\r\n",
        "    z_i = sgat(Wx, nhoods, i)\r\n",
        "    z_i = sigmoid(z_i)\r\n",
        "    z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "for u in range(1, U):\r\n",
        "    sgat = SGAT(new_intermediate_size, 1)\r\n",
        "\r\n",
        "    z_u = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "    z_u = sigmoid(z_u)\r\n",
        "\r\n",
        "    for i in range(1, num_stocks):\r\n",
        "        z_u_i = sgat(Wx, nhoods, i)\r\n",
        "        z_u_i = sigmoid(z_u_i)\r\n",
        "        z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "    \r\n",
        "    z = torch.cat((z, z_u), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDpzJU-BpzTu",
        "outputId": "fe2297c0-0e56-42a1-b839-bce0f521d7e8"
      },
      "source": [
        "print('z.shape', z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z.shape torch.Size([4, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH8yQvp8p6CP"
      },
      "source": [
        "##Final Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhLolFHp_td"
      },
      "source": [
        "linear = nn.Linear(z.shape[1], 1, bias=True)\r\n",
        "sigmoid = nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNdZdAALqgMn",
        "outputId": "10a66c38-2851-4a44-926f-7995753c08ac"
      },
      "source": [
        "sigmoid(linear(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5032],\n",
              "        [0.5310],\n",
              "        [0.5262],\n",
              "        [0.5571]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIpPquknIZ23",
        "outputId": "e585d923-b591-406a-a614-72c87505673b"
      },
      "source": [
        "print(sigmoid(linear(z)).shape)"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}