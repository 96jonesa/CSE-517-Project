{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scaffolding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNb6Y5CAZrIvVaCCjSjPBLP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/96jonesa/CSE-517-Project/blob/main/scaffolding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUxhN7LDSGGz"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bn0eEsGSB3N"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IchYXapSJjH"
      },
      "source": [
        "#GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-YF6GyHzwE2"
      },
      "source": [
        "##GRU\r\n",
        "This is just a wrapper around nn.GRU for the sake of consistency. Used in the Price Encoder, day-level SMI Encoder, and temporal SMI Encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OVZXsnSJH3"
      },
      "source": [
        "class GRU(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, batch_first=False):\r\n",
        "        super(GRU, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.batch_first = batch_first\r\n",
        "\r\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=self.batch_first)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        output, hn = self.gru(input)\r\n",
        "        return output, hn"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRniLDIGSf5Y"
      },
      "source": [
        "#Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDM1G23a0J4V"
      },
      "source": [
        "##LinearAttention\r\n",
        "The attention mechanism used in Feng et. al. Used in the Price Encoder, day-level SMI Encoder, and temporal SMI Encoder. Given input $h$, returns\r\n",
        "$q_t = \\sum_{i=t-T}^T \\beta_i h_i$ where $\\beta_i = \\dfrac{\\exp\\left( u^T \\tanh \\left( W h_i + b \\right) \\right)}{\\sum_{k=t-T}^t \\exp\\left( u^T \\tanh \\left( W h_k + b \\right) \\right)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDJ054vAquLa"
      },
      "source": [
        "# attention weights are softmax(u^T tanh(W input + b)) where W is learned parameter matrix, u is a learned parameter vector, and b is a learned offset\r\n",
        "\r\n",
        "class LinearAttention(nn.Module):\r\n",
        "    def __init__(self, input_size, intermediate_size, weights_size):\r\n",
        "        super(LinearAttention, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.intermediate_size = intermediate_size\r\n",
        "        self.weights_size = weights_size\r\n",
        "\r\n",
        "        self.linear_1 = nn.Linear(self.input_size, self.intermediate_size, bias=True)\r\n",
        "        self.linear_2 = nn.Linear(self.intermediate_size, self.weights_size, bias=False)\r\n",
        "        self.tanh = nn.Tanh()\r\n",
        "        self.softmax = nn.Softmax(dim=2)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        intermediate = self.tanh(self.linear_1(input))\r\n",
        "        attention_weights = self.softmax(self.linear_2(intermediate))\r\n",
        "        attention_weights = attention_weights.permute(0, 2, 1)\r\n",
        "        output_features = torch.bmm(attention_weights, input)\r\n",
        "\r\n",
        "        return output_features"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qkvwOlPW3kt"
      },
      "source": [
        "#Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AMUuaLR06Ph"
      },
      "source": [
        "##Blend\r\n",
        "Applies a learned bilinear transformation to the left and right vectors, then inputs the result to a ReLU non-linearity. Used to obtain Multi-Modal Encodings from Price Encodings and temporal SMI Encodings. Given Price Encodings $q_t$ and temporal SMI Encodings $c_t$, returns\r\n",
        "$x_t = \\mathcal{B} \\left( c_t, q_t \\right) = \\text{ReLU} \\left( q_t^T W c_t + b \\right)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmdq6ozMV1u8"
      },
      "source": [
        "# output is ReLU(left^T W right + b) where W is a learned paramater matrix\r\n",
        "# and b is a learned bias\r\n",
        "\r\n",
        "class Blend(nn.Module):\r\n",
        "    def __init__(self, left_size, right_size, output_size):\r\n",
        "        super(Blend, self).__init__()\r\n",
        "        self.left_size = left_size\r\n",
        "        self.right_size = right_size\r\n",
        "        self.output_size = output_size\r\n",
        "\r\n",
        "        self.bilinear = nn.Bilinear(self.left_size, self.right_size, output_size, bias=True)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "    \r\n",
        "    def forward(self, left, right):\r\n",
        "        output = self.relu(self.bilinear(left, right))\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zknLj7UautA"
      },
      "source": [
        "#Single-Headed Graph Attention Network (SGAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MQfBWhE1XR6"
      },
      "source": [
        "##SharedLinear\r\n",
        "This is just a wrapper around nn.Linear for the sake of consistency. Used to apply a shared linear transformation to all inputs of an SGAT layer. Under current implementation, this should be applied before passing inputs to SGAT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DYXTg2piK_J"
      },
      "source": [
        "# need shared learned parameter matrix W to multiply against each input vector\r\n",
        "\r\n",
        "class SharedLinear(nn.Module):\r\n",
        "    def __init__(self, input_size, output_size):\r\n",
        "        super(SharedLinear, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.output_size = output_size\r\n",
        "        \r\n",
        "        self.linear = nn.Linear(input_size, output_size, bias=False)\r\n",
        "    \r\n",
        "    def forward(self, input):\r\n",
        "        output = self.linear(input)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu7zaUMD10iy"
      },
      "source": [
        "##SGAT\r\n",
        "A single-headed GAT layer. A shared linear transform $W$ is applied to all the nodes *before* passing them as input to this module (by passing them as input to a SharedLinear layer), then a shared self-attention mechanism is applied to each node $i$ in its immediate neighborhood $\\mathcal{N}_i$. For each node $j\\in \\mathcal{N}_i$, normalized attention coefficients $\\alpha_{i,j}$ are computed to represent the importance of the relations between stocks $i$ and $j$. That is,\r\n",
        "$\\alpha_{i,j} = \\dfrac{\\exp ( \\text{LeakyReLU} ( a_w^T [ W x_i \r\n",
        "\\oplus W x_j ] ) )}{\\sum_{k\\in \\mathcal{N}_i} \\exp ( \\text{LeakyReLU} ( a_w^T [ W x_i \\oplus W x_k ] ) )}$\r\n",
        "where $\\oplus$ denotes concatenation and $a_w$ is a learned parameter matrix. An updated feature vector $z_i$ for the $i$-th stock is computed by applying these attention weights to the linearly transformed multi-modal feature vectors of all of the stocks in $\\mathcal{N}_i$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0uaOH5UW2cc"
      },
      "source": [
        "# merge code with MGAT code to form general case GAT code\r\n",
        "\r\n",
        "class SGAT(nn.Module):\r\n",
        "    def __init__(self, input_size, weights_size, leakyrelu_slope=0.01):\r\n",
        "        super(SGAT, self).__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.weights_size = weights_size\r\n",
        "        self.leakyrelu_slope = leakyrelu_slope\r\n",
        "        \r\n",
        "        self.linear = nn.Linear(2 * input_size, weights_size, bias=False)\r\n",
        "        self.leakyrelu = nn.LeakyReLU(self.leakyrelu_slope)\r\n",
        "        self.softmax = nn.Softmax(dim=1)\r\n",
        "\r\n",
        "    def forward(self, input, neighborhoods, index):\r\n",
        "        stock = input[index]\r\n",
        "        neighborhood = neighborhoods[index]\r\n",
        "        stack_stock = stock.expand(len(neighborhood), stock.shape[0])\r\n",
        "        stack_neighbors = input[neighborhood]\r\n",
        "        cat_stock = torch.cat((stack_stock, stack_neighbors), dim=1)\r\n",
        "        print(cat_stock)\r\n",
        "        attention_weights = self.softmax(self.leakyrelu(self.linear(cat_stock)))  # check this\r\n",
        "        output_features = torch.mm(attention_weights.T, stack_neighbors)  # check this\r\n",
        "\r\n",
        "        return output_features"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km8lDrqXkPIR"
      },
      "source": [
        "#MAN-SF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdXk_nhNs8Jm"
      },
      "source": [
        "class MANSF(nn.Module):\r\n",
        "    def __init__(self, T, num_stocks, gru_hidden_size, attn_inter_size, use_embed_size,\r\n",
        "                 blend_size, gat_1_inter_size, gat_2_inter_size, leakyrelu_slope, elu_alpha, U):\r\n",
        "        super(MANSF, self).__init__()\r\n",
        "        self.T = T\r\n",
        "        self.num_stocks = num_stocks\r\n",
        "        self.gru_hidden_size = gru_hidden_size\r\n",
        "        self.attn_inter_size = attn_inter_size\r\n",
        "        self.use_embed_size = use_embed_size\r\n",
        "        self.blend_size = blend_size\r\n",
        "        self.gat_1_inter_size = gat_1_inter_size\r\n",
        "        self.gat_2_inter_size = gat_2_inter_size\r\n",
        "        self.leakyrelu_slope = leakyrelu_slope\r\n",
        "        self.elu_alpha = elu_alpha\r\n",
        "        self.U = U\r\n",
        "\r\n",
        "        self.gru_p = GRU(3, gru_hidden_size, batch_first=True)\r\n",
        "        self.gru_m = GRU(use_embed_size, gru_hidden_size, batch_first=True)\r\n",
        "        self.gru_s = GRU(gru_hidden_size, gru_hidden_size, batch_first=True)\r\n",
        "        self.attn_p = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.attn_m = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.attn_s = LinearAttention(gru_hidden_size, attn_inter_size, 1)\r\n",
        "        self.blend = Blend(use_embed_size, use_embed_size, blend_size)\r\n",
        "        self.shared_linears_1 = []\r\n",
        "        for u in range(U):\r\n",
        "            self.shared_linears_1.append(SharedLinear(blend_size, gat_1_inter_size))\r\n",
        "        self.shared_linears_2 = []\r\n",
        "        for u in range(U):\r\n",
        "            self.shared_linears_2.append(SharedLinear(U * gat_1_inter_size, gat_2_inter_size))\r\n",
        "        self.mgat_1 = []\r\n",
        "        for u in range(U):\r\n",
        "            sgats = []\r\n",
        "            for i in range(num_stocks):\r\n",
        "                sgats.append(SGAT(gat_1_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "            self.mgat_1.append(sgats)\r\n",
        "            #self.mgat_1.append(SGAT(gat_1_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "        self.mgat_2 = []\r\n",
        "        for u in range(U):\r\n",
        "            sgats = []\r\n",
        "            for i in range(num_stocks):\r\n",
        "                sgats.append(SGAT(gat_2_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "            self.mgat_2.append(sgats)\r\n",
        "            #self.mgat_2.append(SGAT(gat_2_inter_size, 1, leakyrelu_slope=leakyrelu_slope))\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        self.elu = nn.ELU(elu_alpha)\r\n",
        "        self.final_linear = nn.Linear(U * gat_2_inter_size, 1, bias=True)\r\n",
        "\r\n",
        "    # p is price data tensor of shape (num_stocks, T, 3), for the day under consideration\r\n",
        "    #\r\n",
        "    # m is smi data list of tensors of shape (num_stocks, K, use_embed_size) of length T,\r\n",
        "    #       where K is the number of tweets for the given stock on the day under consideration\r\n",
        "    #\r\n",
        "    # neighorhoods is a list of adjacency lists, where each stock is indexed with the same\r\n",
        "    #       indices they have in p and m\r\n",
        "    #\r\n",
        "    # TODO: tensorize day-level smi\r\n",
        "    # TODO: tensorize sgat \r\n",
        "    def forward(self, p, m, neighborhoods):\r\n",
        "        ## price encoding\r\n",
        "        h_p, _ = self.gru_p(p)\r\n",
        "        q = self.attn_p(h_p)\r\n",
        "\r\n",
        "        ## smi encoding (day level)\r\n",
        "        r = torch.zeros(self.num_stocks, 0, self.gru_hidden_size)\r\n",
        "        for t in range(self.T):\r\n",
        "            h_m, _ = self.gru_m(m[t])\r\n",
        "            r_t = self.attn_m(h_m)\r\n",
        "            r = torch.cat((r, r_t), 1)\r\n",
        "\r\n",
        "        ## smi encoding (aggregate)\r\n",
        "        h_s, _ = self.gru_s(r)\r\n",
        "        c = self.attn_s(h_s)\r\n",
        "\r\n",
        "        ## blending\r\n",
        "        x = self.blend(q, c)\r\n",
        "\r\n",
        "        ## reshaping (eliminating superfluous dimension)\r\n",
        "        x = x.view(x.shape[0], x.shape[2])\r\n",
        "\r\n",
        "        ## first gat layer\r\n",
        "        #  first head\r\n",
        "        shared_linear = self.shared_linears_1[0]\r\n",
        "        Wx = shared_linear(x)\r\n",
        "        #sgat = self.mgat_1[0]\r\n",
        "        sgat = self.mgat_1[0][0]\r\n",
        "        z = sgat(Wx, neighborhoods, 0)\r\n",
        "        z = self.elu(z)\r\n",
        "\r\n",
        "        for i in range(1, self.num_stocks):\r\n",
        "            sgat = self.mgat_1[0][i]  # this is the fix to the proceeding TODO\r\n",
        "            z_i = sgat(Wx, neighborhoods, i)  # TODO: use fresh SGAT for each stock\r\n",
        "            z_i = self.elu(z_i)\r\n",
        "            z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "        #  remaining heads\r\n",
        "        for u in range(1, self.U):\r\n",
        "            shared_linear = self.shared_linears_1[u]\r\n",
        "            Wx = shared_linear(x)\r\n",
        "            #sgat = self.mgat_1[u]\r\n",
        "            sgat = self.mgat_1[u][0]\r\n",
        "            z_u = sgat(Wx, neighborhoods, 0)\r\n",
        "            z_u = self.elu(z_u)\r\n",
        "\r\n",
        "            for i in range(1, self.num_stocks):\r\n",
        "                sgat = self.mgat_1[u][i]\r\n",
        "                z_u_i = sgat(Wx, neighborhoods, i)\r\n",
        "                z_u_i = self.elu(z_u_i)\r\n",
        "                z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "            \r\n",
        "            z = torch.cat((z, z_u), 1)\r\n",
        "        \r\n",
        "        ## second gat layer\r\n",
        "        #  first head\r\n",
        "        shared_linear = self.shared_linears_2[0]\r\n",
        "        Wx = shared_linear(z)\r\n",
        "        #sgat = self.mgat_2[0]\r\n",
        "        sgat = self.mgat_2[0][0]\r\n",
        "        new_z = sgat(Wx, neighborhoods, 0)\r\n",
        "        new_z = self.sigmoid(new_z)\r\n",
        "\r\n",
        "        for i in range(1, self.num_stocks):\r\n",
        "            sgat = self.mgat_2[0][i]\r\n",
        "            new_z_i = sgat(Wx, neighborhoods, i)\r\n",
        "            new_z_i = self.sigmoid(new_z_i)\r\n",
        "            new_z = torch.cat((new_z, new_z_i), 0)\r\n",
        "\r\n",
        "        #  remaining heads\r\n",
        "        for u in range(1, self.U):\r\n",
        "            shared_linear = self.shared_linears_2[u]\r\n",
        "            Wx = shared_linear(z)\r\n",
        "            #sgat = self.mgat_2[u]\r\n",
        "            sgat = self.mgat_2[u][0]\r\n",
        "            new_z_u = sgat(Wx, neighborhoods, 0)\r\n",
        "            new_z_u = self.sigmoid(new_z_u)\r\n",
        "\r\n",
        "            for i in range(1, self.num_stocks):\r\n",
        "                sgat = self.mgat_2[u][i]\r\n",
        "                new_z_u_i = sgat(Wx, neighborhoods, i)\r\n",
        "                new_z_u_i = self.sigmoid(new_z_u_i)\r\n",
        "                new_z_u = torch.cat((new_z_u, new_z_u_i), 0)\r\n",
        "            \r\n",
        "            new_z = torch.cat((new_z, new_z_u), 1)\r\n",
        "        \r\n",
        "        ## final layer\r\n",
        "        y = self.sigmoid(self.final_linear(new_z))\r\n",
        "\r\n",
        "        ## return result\r\n",
        "        return y"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGJlWH03F6Vm"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOrNDPkGF7Lx"
      },
      "source": [
        "p = torch.tensor([[[1.5, 1.8, 1.2], [1.7, 1.9, 1.3]], [[0.8, 0.9, 0.6], [0.6, 0.7, 0.4]], [[1.9, 2.3, 1.6], [2.1, 2.4, 1.7]]])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5RpydUnHCY_",
        "outputId": "8348fec4-7082-49a7-96c3-d96175ad8fcb"
      },
      "source": [
        "print(p.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajvv409nHEQW"
      },
      "source": [
        "m = [torch.zeros(3,1,64),torch.zeros(3,1,64)]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsW9psWTH5Q0",
        "outputId": "611e7516-d3d9-4f9e-8ff8-b9768edcf2ee"
      },
      "source": [
        "print(m[0].shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm8MhsktIEmL"
      },
      "source": [
        "neighborhoods = [[0,1],[0,1,],[2]]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHhPTGwtITTJ"
      },
      "source": [
        "Y = torch.tensor([[1.0],[0.0],[1.0]])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAxznczuI1Mk",
        "outputId": "b684aa9a-4d00-40d1-f6ff-4fe4f1cae8c6"
      },
      "source": [
        "print(Y.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d71ifgz-I2HP"
      },
      "source": [
        "mansf = MANSF(T=2,\r\n",
        "              num_stocks=3,\r\n",
        "              gru_hidden_size=64,\r\n",
        "              attn_inter_size=32,\r\n",
        "              use_embed_size=64,\r\n",
        "              blend_size=32,\r\n",
        "              gat_1_inter_size=32,\r\n",
        "              gat_2_inter_size=32,\r\n",
        "              leakyrelu_slope=0.01,\r\n",
        "              elu_alpha=1.0,\r\n",
        "              U=8)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPqWqHO3JSes",
        "outputId": "e954e670-b4cc-43e0-9c0f-51b1836a8284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = mansf(p, m, neighborhoods)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0577,  0.0009, -0.0228, -0.0027, -0.0533,  0.0642, -0.0796, -0.0674,\n",
            "          0.0160, -0.0833,  0.0936, -0.0512, -0.0428, -0.0879,  0.0891, -0.0359,\n",
            "         -0.0844, -0.0045, -0.0326,  0.0030, -0.0449,  0.0953, -0.0482,  0.0956,\n",
            "          0.0762, -0.0703, -0.0461,  0.0290, -0.0145, -0.0457, -0.1079, -0.0117,\n",
            "         -0.0577,  0.0009, -0.0228, -0.0027, -0.0533,  0.0642, -0.0796, -0.0674,\n",
            "          0.0160, -0.0833,  0.0936, -0.0512, -0.0428, -0.0879,  0.0891, -0.0359,\n",
            "         -0.0844, -0.0045, -0.0326,  0.0030, -0.0449,  0.0953, -0.0482,  0.0956,\n",
            "          0.0762, -0.0703, -0.0461,  0.0290, -0.0145, -0.0457, -0.1079, -0.0117],\n",
            "        [-0.0577,  0.0009, -0.0228, -0.0027, -0.0533,  0.0642, -0.0796, -0.0674,\n",
            "          0.0160, -0.0833,  0.0936, -0.0512, -0.0428, -0.0879,  0.0891, -0.0359,\n",
            "         -0.0844, -0.0045, -0.0326,  0.0030, -0.0449,  0.0953, -0.0482,  0.0956,\n",
            "          0.0762, -0.0703, -0.0461,  0.0290, -0.0145, -0.0457, -0.1079, -0.0117,\n",
            "         -0.0382,  0.0083, -0.0246,  0.0055, -0.0426,  0.0362, -0.0453, -0.0467,\n",
            "          0.0063, -0.0623,  0.0748, -0.0337, -0.0149, -0.0428,  0.0706, -0.0057,\n",
            "         -0.0565, -0.0049, -0.0186,  0.0064, -0.0359,  0.0624, -0.0305,  0.0600,\n",
            "          0.0626, -0.0366, -0.0316,  0.0005, -0.0296, -0.0411, -0.0547,  0.0034]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0382,  0.0083, -0.0246,  0.0055, -0.0426,  0.0362, -0.0453, -0.0467,\n",
            "          0.0063, -0.0623,  0.0748, -0.0337, -0.0149, -0.0428,  0.0706, -0.0057,\n",
            "         -0.0565, -0.0049, -0.0186,  0.0064, -0.0359,  0.0624, -0.0305,  0.0600,\n",
            "          0.0626, -0.0366, -0.0316,  0.0005, -0.0296, -0.0411, -0.0547,  0.0034,\n",
            "         -0.0577,  0.0009, -0.0228, -0.0027, -0.0533,  0.0642, -0.0796, -0.0674,\n",
            "          0.0160, -0.0833,  0.0936, -0.0512, -0.0428, -0.0879,  0.0891, -0.0359,\n",
            "         -0.0844, -0.0045, -0.0326,  0.0030, -0.0449,  0.0953, -0.0482,  0.0956,\n",
            "          0.0762, -0.0703, -0.0461,  0.0290, -0.0145, -0.0457, -0.1079, -0.0117],\n",
            "        [-0.0382,  0.0083, -0.0246,  0.0055, -0.0426,  0.0362, -0.0453, -0.0467,\n",
            "          0.0063, -0.0623,  0.0748, -0.0337, -0.0149, -0.0428,  0.0706, -0.0057,\n",
            "         -0.0565, -0.0049, -0.0186,  0.0064, -0.0359,  0.0624, -0.0305,  0.0600,\n",
            "          0.0626, -0.0366, -0.0316,  0.0005, -0.0296, -0.0411, -0.0547,  0.0034,\n",
            "         -0.0382,  0.0083, -0.0246,  0.0055, -0.0426,  0.0362, -0.0453, -0.0467,\n",
            "          0.0063, -0.0623,  0.0748, -0.0337, -0.0149, -0.0428,  0.0706, -0.0057,\n",
            "         -0.0565, -0.0049, -0.0186,  0.0064, -0.0359,  0.0624, -0.0305,  0.0600,\n",
            "          0.0626, -0.0366, -0.0316,  0.0005, -0.0296, -0.0411, -0.0547,  0.0034]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0651, -0.0036, -0.0198, -0.0040, -0.0576,  0.0792, -0.0959, -0.0768,\n",
            "          0.0208, -0.0937,  0.1046, -0.0564, -0.0553, -0.1076,  0.0993, -0.0509,\n",
            "         -0.0995, -0.0022, -0.0413, -0.0005, -0.0518,  0.1080, -0.0566,  0.1139,\n",
            "          0.0819, -0.0886, -0.0501,  0.0434, -0.0050, -0.0477, -0.1353, -0.0181,\n",
            "         -0.0651, -0.0036, -0.0198, -0.0040, -0.0576,  0.0792, -0.0959, -0.0768,\n",
            "          0.0208, -0.0937,  0.1046, -0.0564, -0.0553, -0.1076,  0.0993, -0.0509,\n",
            "         -0.0995, -0.0022, -0.0413, -0.0005, -0.0518,  0.1080, -0.0566,  0.1139,\n",
            "          0.0819, -0.0886, -0.0501,  0.0434, -0.0050, -0.0477, -0.1353, -0.0181]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0377,  0.0528, -0.0618, -0.0749, -0.0186,  0.0623,  0.1104, -0.0785,\n",
            "          0.0729, -0.0631,  0.0240,  0.0796, -0.0046, -0.0967,  0.0867, -0.0324,\n",
            "          0.0614, -0.0710,  0.0842,  0.0357,  0.0682, -0.0783,  0.0632, -0.0575,\n",
            "          0.0064,  0.0636,  0.0966,  0.0040, -0.0174, -0.0284, -0.1078, -0.0503,\n",
            "         -0.0377,  0.0528, -0.0618, -0.0749, -0.0186,  0.0623,  0.1104, -0.0785,\n",
            "          0.0729, -0.0631,  0.0240,  0.0796, -0.0046, -0.0967,  0.0867, -0.0324,\n",
            "          0.0614, -0.0710,  0.0842,  0.0357,  0.0682, -0.0783,  0.0632, -0.0575,\n",
            "          0.0064,  0.0636,  0.0966,  0.0040, -0.0174, -0.0284, -0.1078, -0.0503],\n",
            "        [-0.0377,  0.0528, -0.0618, -0.0749, -0.0186,  0.0623,  0.1104, -0.0785,\n",
            "          0.0729, -0.0631,  0.0240,  0.0796, -0.0046, -0.0967,  0.0867, -0.0324,\n",
            "          0.0614, -0.0710,  0.0842,  0.0357,  0.0682, -0.0783,  0.0632, -0.0575,\n",
            "          0.0064,  0.0636,  0.0966,  0.0040, -0.0174, -0.0284, -0.1078, -0.0503,\n",
            "         -0.0460,  0.0313, -0.0667, -0.0564, -0.0250,  0.0500,  0.0579, -0.0471,\n",
            "          0.0521, -0.0350,  0.0042,  0.0766, -0.0005, -0.0669,  0.0584, -0.0475,\n",
            "          0.0282, -0.0396,  0.0543,  0.0565,  0.0400, -0.0383,  0.0470, -0.0233,\n",
            "         -0.0091,  0.0255,  0.0981, -0.0070, -0.0131, -0.0061, -0.1024, -0.0493]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0460,  0.0313, -0.0667, -0.0564, -0.0250,  0.0500,  0.0579, -0.0471,\n",
            "          0.0521, -0.0350,  0.0042,  0.0766, -0.0005, -0.0669,  0.0584, -0.0475,\n",
            "          0.0282, -0.0396,  0.0543,  0.0565,  0.0400, -0.0383,  0.0470, -0.0233,\n",
            "         -0.0091,  0.0255,  0.0981, -0.0070, -0.0131, -0.0061, -0.1024, -0.0493,\n",
            "         -0.0377,  0.0528, -0.0618, -0.0749, -0.0186,  0.0623,  0.1104, -0.0785,\n",
            "          0.0729, -0.0631,  0.0240,  0.0796, -0.0046, -0.0967,  0.0867, -0.0324,\n",
            "          0.0614, -0.0710,  0.0842,  0.0357,  0.0682, -0.0783,  0.0632, -0.0575,\n",
            "          0.0064,  0.0636,  0.0966,  0.0040, -0.0174, -0.0284, -0.1078, -0.0503],\n",
            "        [-0.0460,  0.0313, -0.0667, -0.0564, -0.0250,  0.0500,  0.0579, -0.0471,\n",
            "          0.0521, -0.0350,  0.0042,  0.0766, -0.0005, -0.0669,  0.0584, -0.0475,\n",
            "          0.0282, -0.0396,  0.0543,  0.0565,  0.0400, -0.0383,  0.0470, -0.0233,\n",
            "         -0.0091,  0.0255,  0.0981, -0.0070, -0.0131, -0.0061, -0.1024, -0.0493,\n",
            "         -0.0460,  0.0313, -0.0667, -0.0564, -0.0250,  0.0500,  0.0579, -0.0471,\n",
            "          0.0521, -0.0350,  0.0042,  0.0766, -0.0005, -0.0669,  0.0584, -0.0475,\n",
            "          0.0282, -0.0396,  0.0543,  0.0565,  0.0400, -0.0383,  0.0470, -0.0233,\n",
            "         -0.0091,  0.0255,  0.0981, -0.0070, -0.0131, -0.0061, -0.1024, -0.0493]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0315,  0.0612, -0.0598, -0.0862, -0.0153,  0.0658,  0.1343, -0.0922,\n",
            "          0.0857, -0.0757,  0.0325,  0.0838, -0.0038, -0.1134,  0.1037, -0.0261,\n",
            "          0.0796, -0.0873,  0.0989,  0.0252,  0.0829, -0.0971,  0.0717, -0.0711,\n",
            "          0.0147,  0.0814,  0.0940,  0.0112, -0.0179, -0.0398, -0.1123, -0.0499,\n",
            "         -0.0315,  0.0612, -0.0598, -0.0862, -0.0153,  0.0658,  0.1343, -0.0922,\n",
            "          0.0857, -0.0757,  0.0325,  0.0838, -0.0038, -0.1134,  0.1037, -0.0261,\n",
            "          0.0796, -0.0873,  0.0989,  0.0252,  0.0829, -0.0971,  0.0717, -0.0711,\n",
            "          0.0147,  0.0814,  0.0940,  0.0112, -0.0179, -0.0398, -0.1123, -0.0499]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0381,  0.1353,  0.0354,  0.0020,  0.0079, -0.0660,  0.1000, -0.1071,\n",
            "         -0.0512,  0.0009, -0.0009, -0.0451,  0.0431, -0.0195,  0.0937, -0.0575,\n",
            "          0.1200,  0.0753, -0.0194,  0.0043, -0.0435,  0.1138,  0.0890, -0.0183,\n",
            "         -0.0021,  0.0724, -0.0812,  0.0188, -0.0055, -0.0589, -0.0239,  0.0713,\n",
            "          0.0381,  0.1353,  0.0354,  0.0020,  0.0079, -0.0660,  0.1000, -0.1071,\n",
            "         -0.0512,  0.0009, -0.0009, -0.0451,  0.0431, -0.0195,  0.0937, -0.0575,\n",
            "          0.1200,  0.0753, -0.0194,  0.0043, -0.0435,  0.1138,  0.0890, -0.0183,\n",
            "         -0.0021,  0.0724, -0.0812,  0.0188, -0.0055, -0.0589, -0.0239,  0.0713],\n",
            "        [ 0.0381,  0.1353,  0.0354,  0.0020,  0.0079, -0.0660,  0.1000, -0.1071,\n",
            "         -0.0512,  0.0009, -0.0009, -0.0451,  0.0431, -0.0195,  0.0937, -0.0575,\n",
            "          0.1200,  0.0753, -0.0194,  0.0043, -0.0435,  0.1138,  0.0890, -0.0183,\n",
            "         -0.0021,  0.0724, -0.0812,  0.0188, -0.0055, -0.0589, -0.0239,  0.0713,\n",
            "          0.0287,  0.0564,  0.0456, -0.0319,  0.0202, -0.0472,  0.0730, -0.0747,\n",
            "         -0.0222,  0.0074, -0.0095, -0.0101,  0.0344, -0.0195,  0.0609, -0.0428,\n",
            "          0.0668,  0.0284,  0.0016,  0.0228, -0.0250,  0.0807,  0.0647, -0.0113,\n",
            "         -0.0151,  0.0477, -0.0320,  0.0139, -0.0185, -0.0252, -0.0264,  0.0374]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0287,  0.0564,  0.0456, -0.0319,  0.0202, -0.0472,  0.0730, -0.0747,\n",
            "         -0.0222,  0.0074, -0.0095, -0.0101,  0.0344, -0.0195,  0.0609, -0.0428,\n",
            "          0.0668,  0.0284,  0.0016,  0.0228, -0.0250,  0.0807,  0.0647, -0.0113,\n",
            "         -0.0151,  0.0477, -0.0320,  0.0139, -0.0185, -0.0252, -0.0264,  0.0374,\n",
            "          0.0381,  0.1353,  0.0354,  0.0020,  0.0079, -0.0660,  0.1000, -0.1071,\n",
            "         -0.0512,  0.0009, -0.0009, -0.0451,  0.0431, -0.0195,  0.0937, -0.0575,\n",
            "          0.1200,  0.0753, -0.0194,  0.0043, -0.0435,  0.1138,  0.0890, -0.0183,\n",
            "         -0.0021,  0.0724, -0.0812,  0.0188, -0.0055, -0.0589, -0.0239,  0.0713],\n",
            "        [ 0.0287,  0.0564,  0.0456, -0.0319,  0.0202, -0.0472,  0.0730, -0.0747,\n",
            "         -0.0222,  0.0074, -0.0095, -0.0101,  0.0344, -0.0195,  0.0609, -0.0428,\n",
            "          0.0668,  0.0284,  0.0016,  0.0228, -0.0250,  0.0807,  0.0647, -0.0113,\n",
            "         -0.0151,  0.0477, -0.0320,  0.0139, -0.0185, -0.0252, -0.0264,  0.0374,\n",
            "          0.0287,  0.0564,  0.0456, -0.0319,  0.0202, -0.0472,  0.0730, -0.0747,\n",
            "         -0.0222,  0.0074, -0.0095, -0.0101,  0.0344, -0.0195,  0.0609, -0.0428,\n",
            "          0.0668,  0.0284,  0.0016,  0.0228, -0.0250,  0.0807,  0.0647, -0.0113,\n",
            "         -0.0151,  0.0477, -0.0320,  0.0139, -0.0185, -0.0252, -0.0264,  0.0374]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0449,  0.1708,  0.0339,  0.0185,  0.0046, -0.0725,  0.1110, -0.1238,\n",
            "         -0.0649, -0.0055,  0.0019, -0.0613,  0.0479, -0.0201,  0.1121, -0.0624,\n",
            "          0.1449,  0.0978, -0.0275, -0.0043, -0.0545,  0.1276,  0.1020, -0.0212,\n",
            "          0.0036,  0.0867, -0.1052,  0.0197,  0.0014, -0.0734, -0.0207,  0.0879,\n",
            "          0.0449,  0.1708,  0.0339,  0.0185,  0.0046, -0.0725,  0.1110, -0.1238,\n",
            "         -0.0649, -0.0055,  0.0019, -0.0613,  0.0479, -0.0201,  0.1121, -0.0624,\n",
            "          0.1449,  0.0978, -0.0275, -0.0043, -0.0545,  0.1276,  0.1020, -0.0212,\n",
            "          0.0036,  0.0867, -0.1052,  0.0197,  0.0014, -0.0734, -0.0207,  0.0879]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0319,  0.0177,  0.0671,  0.0429,  0.0591,  0.0308, -0.1253,  0.0328,\n",
            "          0.0453,  0.1085,  0.0070, -0.0170,  0.0332,  0.0792,  0.0127,  0.0527,\n",
            "         -0.0591, -0.0453,  0.0864, -0.0336, -0.0680, -0.0798,  0.0153, -0.0267,\n",
            "         -0.0383, -0.0637,  0.0058,  0.0922, -0.0254,  0.0915, -0.0645,  0.1224,\n",
            "         -0.0319,  0.0177,  0.0671,  0.0429,  0.0591,  0.0308, -0.1253,  0.0328,\n",
            "          0.0453,  0.1085,  0.0070, -0.0170,  0.0332,  0.0792,  0.0127,  0.0527,\n",
            "         -0.0591, -0.0453,  0.0864, -0.0336, -0.0680, -0.0798,  0.0153, -0.0267,\n",
            "         -0.0383, -0.0637,  0.0058,  0.0922, -0.0254,  0.0915, -0.0645,  0.1224],\n",
            "        [-0.0319,  0.0177,  0.0671,  0.0429,  0.0591,  0.0308, -0.1253,  0.0328,\n",
            "          0.0453,  0.1085,  0.0070, -0.0170,  0.0332,  0.0792,  0.0127,  0.0527,\n",
            "         -0.0591, -0.0453,  0.0864, -0.0336, -0.0680, -0.0798,  0.0153, -0.0267,\n",
            "         -0.0383, -0.0637,  0.0058,  0.0922, -0.0254,  0.0915, -0.0645,  0.1224,\n",
            "         -0.0404, -0.0014,  0.0489,  0.0002,  0.0310,  0.0035, -0.0604, -0.0034,\n",
            "          0.0513,  0.0852,  0.0183, -0.0107,  0.0289,  0.0495,  0.0186,  0.0363,\n",
            "         -0.0215, -0.0308,  0.0711, -0.0289, -0.0380, -0.0219,  0.0255, -0.0282,\n",
            "         -0.0205, -0.0344,  0.0155,  0.0677, -0.0027,  0.0539, -0.0282,  0.1095]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0404, -0.0014,  0.0489,  0.0002,  0.0310,  0.0035, -0.0604, -0.0034,\n",
            "          0.0513,  0.0852,  0.0183, -0.0107,  0.0289,  0.0495,  0.0186,  0.0363,\n",
            "         -0.0215, -0.0308,  0.0711, -0.0289, -0.0380, -0.0219,  0.0255, -0.0282,\n",
            "         -0.0205, -0.0344,  0.0155,  0.0677, -0.0027,  0.0539, -0.0282,  0.1095,\n",
            "         -0.0319,  0.0177,  0.0671,  0.0429,  0.0591,  0.0308, -0.1253,  0.0328,\n",
            "          0.0453,  0.1085,  0.0070, -0.0170,  0.0332,  0.0792,  0.0127,  0.0527,\n",
            "         -0.0591, -0.0453,  0.0864, -0.0336, -0.0680, -0.0798,  0.0153, -0.0267,\n",
            "         -0.0383, -0.0637,  0.0058,  0.0922, -0.0254,  0.0915, -0.0645,  0.1224],\n",
            "        [-0.0404, -0.0014,  0.0489,  0.0002,  0.0310,  0.0035, -0.0604, -0.0034,\n",
            "          0.0513,  0.0852,  0.0183, -0.0107,  0.0289,  0.0495,  0.0186,  0.0363,\n",
            "         -0.0215, -0.0308,  0.0711, -0.0289, -0.0380, -0.0219,  0.0255, -0.0282,\n",
            "         -0.0205, -0.0344,  0.0155,  0.0677, -0.0027,  0.0539, -0.0282,  0.1095,\n",
            "         -0.0404, -0.0014,  0.0489,  0.0002,  0.0310,  0.0035, -0.0604, -0.0034,\n",
            "          0.0513,  0.0852,  0.0183, -0.0107,  0.0289,  0.0495,  0.0186,  0.0363,\n",
            "         -0.0215, -0.0308,  0.0711, -0.0289, -0.0380, -0.0219,  0.0255, -0.0282,\n",
            "         -0.0205, -0.0344,  0.0155,  0.0677, -0.0027,  0.0539, -0.0282,  0.1095]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0271,  0.0277,  0.0776,  0.0632,  0.0737,  0.0417, -0.1583,  0.0487,\n",
            "          0.0430,  0.1225,  0.0009, -0.0213,  0.0356,  0.0922,  0.0088,  0.0631,\n",
            "         -0.0756, -0.0541,  0.0938, -0.0359, -0.0843, -0.1069,  0.0112, -0.0245,\n",
            "         -0.0470, -0.0791,  0.0012,  0.1029, -0.0366,  0.1109, -0.0832,  0.1307,\n",
            "         -0.0271,  0.0277,  0.0776,  0.0632,  0.0737,  0.0417, -0.1583,  0.0487,\n",
            "          0.0430,  0.1225,  0.0009, -0.0213,  0.0356,  0.0922,  0.0088,  0.0631,\n",
            "         -0.0756, -0.0541,  0.0938, -0.0359, -0.0843, -0.1069,  0.0112, -0.0245,\n",
            "         -0.0470, -0.0791,  0.0012,  0.1029, -0.0366,  0.1109, -0.0832,  0.1307]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.1120,  0.0378,  0.0831, -0.0710,  0.0520, -0.0019,  0.0068,  0.0770,\n",
            "          0.0627,  0.0218,  0.0392, -0.0150, -0.0415, -0.0081, -0.0830, -0.0464,\n",
            "         -0.0603, -0.0203, -0.0687,  0.0274,  0.1501,  0.0577, -0.0529, -0.0444,\n",
            "          0.0839, -0.0394,  0.0711, -0.0459,  0.1588, -0.0070,  0.0626, -0.0414,\n",
            "         -0.1120,  0.0378,  0.0831, -0.0710,  0.0520, -0.0019,  0.0068,  0.0770,\n",
            "          0.0627,  0.0218,  0.0392, -0.0150, -0.0415, -0.0081, -0.0830, -0.0464,\n",
            "         -0.0603, -0.0203, -0.0687,  0.0274,  0.1501,  0.0577, -0.0529, -0.0444,\n",
            "          0.0839, -0.0394,  0.0711, -0.0459,  0.1588, -0.0070,  0.0626, -0.0414],\n",
            "        [-0.1120,  0.0378,  0.0831, -0.0710,  0.0520, -0.0019,  0.0068,  0.0770,\n",
            "          0.0627,  0.0218,  0.0392, -0.0150, -0.0415, -0.0081, -0.0830, -0.0464,\n",
            "         -0.0603, -0.0203, -0.0687,  0.0274,  0.1501,  0.0577, -0.0529, -0.0444,\n",
            "          0.0839, -0.0394,  0.0711, -0.0459,  0.1588, -0.0070,  0.0626, -0.0414,\n",
            "         -0.0811,  0.0160,  0.0481, -0.0313,  0.0448, -0.0429, -0.0044,  0.0501,\n",
            "          0.0273,  0.0152,  0.0209, -0.0137, -0.0255, -0.0250, -0.0587, -0.0415,\n",
            "         -0.0364,  0.0024, -0.0611,  0.0317,  0.1121,  0.0506, -0.0193, -0.0339,\n",
            "          0.0486, -0.0194,  0.0487, -0.0143,  0.0978, -0.0186,  0.0475, -0.0157]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0811,  0.0160,  0.0481, -0.0313,  0.0448, -0.0429, -0.0044,  0.0501,\n",
            "          0.0273,  0.0152,  0.0209, -0.0137, -0.0255, -0.0250, -0.0587, -0.0415,\n",
            "         -0.0364,  0.0024, -0.0611,  0.0317,  0.1121,  0.0506, -0.0193, -0.0339,\n",
            "          0.0486, -0.0194,  0.0487, -0.0143,  0.0978, -0.0186,  0.0475, -0.0157,\n",
            "         -0.1120,  0.0378,  0.0831, -0.0710,  0.0520, -0.0019,  0.0068,  0.0770,\n",
            "          0.0627,  0.0218,  0.0392, -0.0150, -0.0415, -0.0081, -0.0830, -0.0464,\n",
            "         -0.0603, -0.0203, -0.0687,  0.0274,  0.1501,  0.0577, -0.0529, -0.0444,\n",
            "          0.0839, -0.0394,  0.0711, -0.0459,  0.1588, -0.0070,  0.0626, -0.0414],\n",
            "        [-0.0811,  0.0160,  0.0481, -0.0313,  0.0448, -0.0429, -0.0044,  0.0501,\n",
            "          0.0273,  0.0152,  0.0209, -0.0137, -0.0255, -0.0250, -0.0587, -0.0415,\n",
            "         -0.0364,  0.0024, -0.0611,  0.0317,  0.1121,  0.0506, -0.0193, -0.0339,\n",
            "          0.0486, -0.0194,  0.0487, -0.0143,  0.0978, -0.0186,  0.0475, -0.0157,\n",
            "         -0.0811,  0.0160,  0.0481, -0.0313,  0.0448, -0.0429, -0.0044,  0.0501,\n",
            "          0.0273,  0.0152,  0.0209, -0.0137, -0.0255, -0.0250, -0.0587, -0.0415,\n",
            "         -0.0364,  0.0024, -0.0611,  0.0317,  0.1121,  0.0506, -0.0193, -0.0339,\n",
            "          0.0486, -0.0194,  0.0487, -0.0143,  0.0978, -0.0186,  0.0475, -0.0157]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.1243,  0.0459,  0.1018, -0.0878,  0.0567,  0.0166,  0.0088,  0.0912,\n",
            "          0.0779,  0.0249,  0.0498, -0.0167, -0.0480, -0.0012, -0.0942, -0.0482,\n",
            "         -0.0725, -0.0336, -0.0719,  0.0258,  0.1671,  0.0602, -0.0714, -0.0500,\n",
            "          0.1026, -0.0506,  0.0833, -0.0625,  0.1874, -0.0013,  0.0681, -0.0526,\n",
            "         -0.1243,  0.0459,  0.1018, -0.0878,  0.0567,  0.0166,  0.0088,  0.0912,\n",
            "          0.0779,  0.0249,  0.0498, -0.0167, -0.0480, -0.0012, -0.0942, -0.0482,\n",
            "         -0.0725, -0.0336, -0.0719,  0.0258,  0.1671,  0.0602, -0.0714, -0.0500,\n",
            "          0.1026, -0.0506,  0.0833, -0.0625,  0.1874, -0.0013,  0.0681, -0.0526]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0177, -0.0903, -0.0571,  0.0141,  0.0487, -0.0138,  0.0064, -0.0884,\n",
            "          0.0919, -0.1186, -0.0258,  0.0521, -0.0104, -0.0733,  0.0612, -0.0050,\n",
            "          0.0446,  0.0512,  0.1343,  0.0071,  0.0428,  0.0227,  0.0838,  0.0424,\n",
            "          0.0221,  0.0976, -0.0436,  0.0618, -0.0031,  0.0319,  0.0099, -0.0791,\n",
            "         -0.0177, -0.0903, -0.0571,  0.0141,  0.0487, -0.0138,  0.0064, -0.0884,\n",
            "          0.0919, -0.1186, -0.0258,  0.0521, -0.0104, -0.0733,  0.0612, -0.0050,\n",
            "          0.0446,  0.0512,  0.1343,  0.0071,  0.0428,  0.0227,  0.0838,  0.0424,\n",
            "          0.0221,  0.0976, -0.0436,  0.0618, -0.0031,  0.0319,  0.0099, -0.0791],\n",
            "        [-0.0177, -0.0903, -0.0571,  0.0141,  0.0487, -0.0138,  0.0064, -0.0884,\n",
            "          0.0919, -0.1186, -0.0258,  0.0521, -0.0104, -0.0733,  0.0612, -0.0050,\n",
            "          0.0446,  0.0512,  0.1343,  0.0071,  0.0428,  0.0227,  0.0838,  0.0424,\n",
            "          0.0221,  0.0976, -0.0436,  0.0618, -0.0031,  0.0319,  0.0099, -0.0791,\n",
            "         -0.0063, -0.0702, -0.0381,  0.0208,  0.0141, -0.0188, -0.0131, -0.0864,\n",
            "          0.0464, -0.0870, -0.0060,  0.0492, -0.0081, -0.0412,  0.0536, -0.0019,\n",
            "          0.0442,  0.0258,  0.0985,  0.0052,  0.0274,  0.0157,  0.0563,  0.0180,\n",
            "          0.0105,  0.0606, -0.0272,  0.0227,  0.0006,  0.0134,  0.0235, -0.0360]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0063, -0.0702, -0.0381,  0.0208,  0.0141, -0.0188, -0.0131, -0.0864,\n",
            "          0.0464, -0.0870, -0.0060,  0.0492, -0.0081, -0.0412,  0.0536, -0.0019,\n",
            "          0.0442,  0.0258,  0.0985,  0.0052,  0.0274,  0.0157,  0.0563,  0.0180,\n",
            "          0.0105,  0.0606, -0.0272,  0.0227,  0.0006,  0.0134,  0.0235, -0.0360,\n",
            "         -0.0177, -0.0903, -0.0571,  0.0141,  0.0487, -0.0138,  0.0064, -0.0884,\n",
            "          0.0919, -0.1186, -0.0258,  0.0521, -0.0104, -0.0733,  0.0612, -0.0050,\n",
            "          0.0446,  0.0512,  0.1343,  0.0071,  0.0428,  0.0227,  0.0838,  0.0424,\n",
            "          0.0221,  0.0976, -0.0436,  0.0618, -0.0031,  0.0319,  0.0099, -0.0791],\n",
            "        [-0.0063, -0.0702, -0.0381,  0.0208,  0.0141, -0.0188, -0.0131, -0.0864,\n",
            "          0.0464, -0.0870, -0.0060,  0.0492, -0.0081, -0.0412,  0.0536, -0.0019,\n",
            "          0.0442,  0.0258,  0.0985,  0.0052,  0.0274,  0.0157,  0.0563,  0.0180,\n",
            "          0.0105,  0.0606, -0.0272,  0.0227,  0.0006,  0.0134,  0.0235, -0.0360,\n",
            "         -0.0063, -0.0702, -0.0381,  0.0208,  0.0141, -0.0188, -0.0131, -0.0864,\n",
            "          0.0464, -0.0870, -0.0060,  0.0492, -0.0081, -0.0412,  0.0536, -0.0019,\n",
            "          0.0442,  0.0258,  0.0985,  0.0052,  0.0274,  0.0157,  0.0563,  0.0180,\n",
            "          0.0105,  0.0606, -0.0272,  0.0227,  0.0006,  0.0134,  0.0235, -0.0360]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0229, -0.1012, -0.0668,  0.0125,  0.0666, -0.0103,  0.0184, -0.0909,\n",
            "          0.1121, -0.1362, -0.0346,  0.0519, -0.0156, -0.0894,  0.0641, -0.0036,\n",
            "          0.0478,  0.0647,  0.1512,  0.0097,  0.0477,  0.0243,  0.0947,  0.0519,\n",
            "          0.0318,  0.1173, -0.0499,  0.0824, -0.0050,  0.0375,  0.0025, -0.1002,\n",
            "         -0.0229, -0.1012, -0.0668,  0.0125,  0.0666, -0.0103,  0.0184, -0.0909,\n",
            "          0.1121, -0.1362, -0.0346,  0.0519, -0.0156, -0.0894,  0.0641, -0.0036,\n",
            "          0.0478,  0.0647,  0.1512,  0.0097,  0.0477,  0.0243,  0.0947,  0.0519,\n",
            "          0.0318,  0.1173, -0.0499,  0.0824, -0.0050,  0.0375,  0.0025, -0.1002]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0372, -0.0330,  0.0149,  0.1180, -0.0167, -0.0531, -0.0067, -0.0550,\n",
            "          0.0975, -0.0412, -0.0450, -0.0260,  0.0711, -0.1137,  0.0383,  0.0016,\n",
            "          0.0055, -0.0058,  0.0680, -0.0176, -0.0079, -0.0317,  0.0545,  0.0113,\n",
            "         -0.0883, -0.0197,  0.0143, -0.0202, -0.0017,  0.0207, -0.0456, -0.0429,\n",
            "         -0.0372, -0.0330,  0.0149,  0.1180, -0.0167, -0.0531, -0.0067, -0.0550,\n",
            "          0.0975, -0.0412, -0.0450, -0.0260,  0.0711, -0.1137,  0.0383,  0.0016,\n",
            "          0.0055, -0.0058,  0.0680, -0.0176, -0.0079, -0.0317,  0.0545,  0.0113,\n",
            "         -0.0883, -0.0197,  0.0143, -0.0202, -0.0017,  0.0207, -0.0456, -0.0429],\n",
            "        [-0.0372, -0.0330,  0.0149,  0.1180, -0.0167, -0.0531, -0.0067, -0.0550,\n",
            "          0.0975, -0.0412, -0.0450, -0.0260,  0.0711, -0.1137,  0.0383,  0.0016,\n",
            "          0.0055, -0.0058,  0.0680, -0.0176, -0.0079, -0.0317,  0.0545,  0.0113,\n",
            "         -0.0883, -0.0197,  0.0143, -0.0202, -0.0017,  0.0207, -0.0456, -0.0429,\n",
            "         -0.0136, -0.0295, -0.0167,  0.0579,  0.0028, -0.0358, -0.0262, -0.0451,\n",
            "          0.0570, -0.0230, -0.0222, -0.0195,  0.0568, -0.0538,  0.0343, -0.0005,\n",
            "         -0.0204, -0.0299,  0.0311, -0.0212, -0.0050,  0.0090,  0.0228,  0.0016,\n",
            "         -0.0537, -0.0081, -0.0094, -0.0089,  0.0032,  0.0237, -0.0350, -0.0102]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0136, -0.0295, -0.0167,  0.0579,  0.0028, -0.0358, -0.0262, -0.0451,\n",
            "          0.0570, -0.0230, -0.0222, -0.0195,  0.0568, -0.0538,  0.0343, -0.0005,\n",
            "         -0.0204, -0.0299,  0.0311, -0.0212, -0.0050,  0.0090,  0.0228,  0.0016,\n",
            "         -0.0537, -0.0081, -0.0094, -0.0089,  0.0032,  0.0237, -0.0350, -0.0102,\n",
            "         -0.0372, -0.0330,  0.0149,  0.1180, -0.0167, -0.0531, -0.0067, -0.0550,\n",
            "          0.0975, -0.0412, -0.0450, -0.0260,  0.0711, -0.1137,  0.0383,  0.0016,\n",
            "          0.0055, -0.0058,  0.0680, -0.0176, -0.0079, -0.0317,  0.0545,  0.0113,\n",
            "         -0.0883, -0.0197,  0.0143, -0.0202, -0.0017,  0.0207, -0.0456, -0.0429],\n",
            "        [-0.0136, -0.0295, -0.0167,  0.0579,  0.0028, -0.0358, -0.0262, -0.0451,\n",
            "          0.0570, -0.0230, -0.0222, -0.0195,  0.0568, -0.0538,  0.0343, -0.0005,\n",
            "         -0.0204, -0.0299,  0.0311, -0.0212, -0.0050,  0.0090,  0.0228,  0.0016,\n",
            "         -0.0537, -0.0081, -0.0094, -0.0089,  0.0032,  0.0237, -0.0350, -0.0102,\n",
            "         -0.0136, -0.0295, -0.0167,  0.0579,  0.0028, -0.0358, -0.0262, -0.0451,\n",
            "          0.0570, -0.0230, -0.0222, -0.0195,  0.0568, -0.0538,  0.0343, -0.0005,\n",
            "         -0.0204, -0.0299,  0.0311, -0.0212, -0.0050,  0.0090,  0.0228,  0.0016,\n",
            "         -0.0537, -0.0081, -0.0094, -0.0089,  0.0032,  0.0237, -0.0350, -0.0102]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0518, -0.0358,  0.0310,  0.1474, -0.0282, -0.0613,  0.0009, -0.0589,\n",
            "          0.1161, -0.0496, -0.0585, -0.0283,  0.0779, -0.1420,  0.0431,  0.0049,\n",
            "          0.0211,  0.0054,  0.0876, -0.0138, -0.0113, -0.0531,  0.0702,  0.0175,\n",
            "         -0.1060, -0.0261,  0.0274, -0.0277, -0.0057,  0.0216, -0.0492, -0.0577,\n",
            "         -0.0518, -0.0358,  0.0310,  0.1474, -0.0282, -0.0613,  0.0009, -0.0589,\n",
            "          0.1161, -0.0496, -0.0585, -0.0283,  0.0779, -0.1420,  0.0431,  0.0049,\n",
            "          0.0211,  0.0054,  0.0876, -0.0138, -0.0113, -0.0531,  0.0702,  0.0175,\n",
            "         -0.1060, -0.0261,  0.0274, -0.0277, -0.0057,  0.0216, -0.0492, -0.0577]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0025,  0.0175, -0.0119,  0.0523, -0.0066,  0.0472,  0.0477,  0.0245,\n",
            "          0.0073,  0.0250, -0.0319,  0.0348, -0.0962,  0.1248,  0.0065, -0.0036,\n",
            "          0.0683, -0.0215,  0.0206, -0.0620,  0.1420, -0.0212,  0.0048,  0.0974,\n",
            "         -0.0072, -0.0054, -0.0265,  0.0714, -0.0128,  0.0702, -0.0214, -0.0247,\n",
            "         -0.0025,  0.0175, -0.0119,  0.0523, -0.0066,  0.0472,  0.0477,  0.0245,\n",
            "          0.0073,  0.0250, -0.0319,  0.0348, -0.0962,  0.1248,  0.0065, -0.0036,\n",
            "          0.0683, -0.0215,  0.0206, -0.0620,  0.1420, -0.0212,  0.0048,  0.0974,\n",
            "         -0.0072, -0.0054, -0.0265,  0.0714, -0.0128,  0.0702, -0.0214, -0.0247],\n",
            "        [-0.0025,  0.0175, -0.0119,  0.0523, -0.0066,  0.0472,  0.0477,  0.0245,\n",
            "          0.0073,  0.0250, -0.0319,  0.0348, -0.0962,  0.1248,  0.0065, -0.0036,\n",
            "          0.0683, -0.0215,  0.0206, -0.0620,  0.1420, -0.0212,  0.0048,  0.0974,\n",
            "         -0.0072, -0.0054, -0.0265,  0.0714, -0.0128,  0.0702, -0.0214, -0.0247,\n",
            "          0.0074, -0.0088, -0.0092,  0.0292, -0.0094,  0.0422,  0.0158,  0.0159,\n",
            "          0.0154,  0.0063,  0.0082,  0.0134, -0.0783,  0.0556,  0.0171,  0.0274,\n",
            "          0.0585, -0.0197,  0.0072, -0.0641,  0.1226, -0.0125,  0.0193,  0.0463,\n",
            "         -0.0238,  0.0170, -0.0071,  0.0691,  0.0011,  0.0295, -0.0131, -0.0080]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0074, -0.0088, -0.0092,  0.0292, -0.0094,  0.0422,  0.0158,  0.0159,\n",
            "          0.0154,  0.0063,  0.0082,  0.0134, -0.0783,  0.0556,  0.0171,  0.0274,\n",
            "          0.0585, -0.0197,  0.0072, -0.0641,  0.1226, -0.0125,  0.0193,  0.0463,\n",
            "         -0.0238,  0.0170, -0.0071,  0.0691,  0.0011,  0.0295, -0.0131, -0.0080,\n",
            "         -0.0025,  0.0175, -0.0119,  0.0523, -0.0066,  0.0472,  0.0477,  0.0245,\n",
            "          0.0073,  0.0250, -0.0319,  0.0348, -0.0962,  0.1248,  0.0065, -0.0036,\n",
            "          0.0683, -0.0215,  0.0206, -0.0620,  0.1420, -0.0212,  0.0048,  0.0974,\n",
            "         -0.0072, -0.0054, -0.0265,  0.0714, -0.0128,  0.0702, -0.0214, -0.0247],\n",
            "        [ 0.0074, -0.0088, -0.0092,  0.0292, -0.0094,  0.0422,  0.0158,  0.0159,\n",
            "          0.0154,  0.0063,  0.0082,  0.0134, -0.0783,  0.0556,  0.0171,  0.0274,\n",
            "          0.0585, -0.0197,  0.0072, -0.0641,  0.1226, -0.0125,  0.0193,  0.0463,\n",
            "         -0.0238,  0.0170, -0.0071,  0.0691,  0.0011,  0.0295, -0.0131, -0.0080,\n",
            "          0.0074, -0.0088, -0.0092,  0.0292, -0.0094,  0.0422,  0.0158,  0.0159,\n",
            "          0.0154,  0.0063,  0.0082,  0.0134, -0.0783,  0.0556,  0.0171,  0.0274,\n",
            "          0.0585, -0.0197,  0.0072, -0.0641,  0.1226, -0.0125,  0.0193,  0.0463,\n",
            "         -0.0238,  0.0170, -0.0071,  0.0691,  0.0011,  0.0295, -0.0131, -0.0080]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0088,  0.0314, -0.0147,  0.0644, -0.0051,  0.0502,  0.0623,  0.0304,\n",
            "          0.0046,  0.0330, -0.0538,  0.0422, -0.1027,  0.1578,  0.0033, -0.0177,\n",
            "          0.0737, -0.0216,  0.0250, -0.0610,  0.1533, -0.0273,  0.0010,  0.1245,\n",
            "         -0.0017, -0.0155, -0.0350,  0.0715, -0.0217,  0.0880, -0.0270, -0.0355,\n",
            "         -0.0088,  0.0314, -0.0147,  0.0644, -0.0051,  0.0502,  0.0623,  0.0304,\n",
            "          0.0046,  0.0330, -0.0538,  0.0422, -0.1027,  0.1578,  0.0033, -0.0177,\n",
            "          0.0737, -0.0216,  0.0250, -0.0610,  0.1533, -0.0273,  0.0010,  0.1245,\n",
            "         -0.0017, -0.0155, -0.0350,  0.0715, -0.0217,  0.0880, -0.0270, -0.0355]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315,\n",
            "          0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315],\n",
            "        [ 0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315,\n",
            "          0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315,\n",
            "          0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315],\n",
            "        [ 0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315,\n",
            "          0.0172,  0.0587,  0.0460, -0.0461, -0.0532, -0.0600, -0.0263, -0.0772,\n",
            "          0.0032,  0.0454,  0.0375, -0.0288, -0.0306,  0.0788,  0.1560,  0.0356,\n",
            "         -0.0023,  0.0833, -0.0180, -0.0234,  0.0025,  0.1258,  0.0054, -0.0279,\n",
            "          0.0252, -0.0452,  0.0434, -0.0104,  0.0550, -0.0491, -0.0640,  0.0315]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0174,  0.0345,  0.0424, -0.0171, -0.0229, -0.0403, -0.0280, -0.0541,\n",
            "          0.0013,  0.0269,  0.0259, -0.0037, -0.0167,  0.0599,  0.0968,  0.0252,\n",
            "         -0.0052,  0.0638, -0.0199, -0.0102,  0.0047,  0.0837, -0.0167, -0.0140,\n",
            "          0.0081, -0.0264,  0.0366, -0.0099,  0.0385, -0.0561, -0.0578,  0.0160,\n",
            "          0.0174,  0.0345,  0.0424, -0.0171, -0.0229, -0.0403, -0.0280, -0.0541,\n",
            "          0.0013,  0.0269,  0.0259, -0.0037, -0.0167,  0.0599,  0.0968,  0.0252,\n",
            "         -0.0052,  0.0638, -0.0199, -0.0102,  0.0047,  0.0837, -0.0167, -0.0140,\n",
            "          0.0081, -0.0264,  0.0366, -0.0099,  0.0385, -0.0561, -0.0578,  0.0160]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089,\n",
            "         -0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089],\n",
            "        [-0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089,\n",
            "         -0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089,\n",
            "         -0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089],\n",
            "        [-0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089,\n",
            "         -0.0255,  0.0150,  0.0378,  0.0138,  0.0790, -0.0363,  0.0534,  0.0655,\n",
            "          0.0093,  0.0666,  0.0762, -0.0874,  0.0776, -0.0811, -0.0933, -0.0560,\n",
            "          0.0289,  0.0593, -0.0300,  0.0581, -0.0319, -0.0136, -0.1075, -0.0271,\n",
            "          0.0440,  0.0037,  0.0112, -0.0278,  0.0042,  0.0482,  0.0206,  0.0089]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0044,  0.0015,  0.0237,  0.0193,  0.0393, -0.0396,  0.0285,  0.0462,\n",
            "          0.0114,  0.0497,  0.0469, -0.0730,  0.0584, -0.0507, -0.0730, -0.0332,\n",
            "          0.0043,  0.0486, -0.0273,  0.0481, -0.0270, -0.0029, -0.0781, -0.0192,\n",
            "          0.0325,  0.0239,  0.0273, -0.0111,  0.0196,  0.0185,  0.0158,  0.0278,\n",
            "         -0.0044,  0.0015,  0.0237,  0.0193,  0.0393, -0.0396,  0.0285,  0.0462,\n",
            "          0.0114,  0.0497,  0.0469, -0.0730,  0.0584, -0.0507, -0.0730, -0.0332,\n",
            "          0.0043,  0.0486, -0.0273,  0.0481, -0.0270, -0.0029, -0.0781, -0.0192,\n",
            "          0.0325,  0.0239,  0.0273, -0.0111,  0.0196,  0.0185,  0.0158,  0.0278]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014,\n",
            "          0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014],\n",
            "        [ 0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014,\n",
            "          0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014,\n",
            "          0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014],\n",
            "        [ 0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014,\n",
            "          0.0233, -0.0273, -0.0672,  0.0066,  0.0737, -0.0937, -0.0787,  0.1085,\n",
            "         -0.0049,  0.0138, -0.0780,  0.0346,  0.0493, -0.0180,  0.0205, -0.0317,\n",
            "          0.0737,  0.0520,  0.0567, -0.0672,  0.0091, -0.0447,  0.0526, -0.0171,\n",
            "          0.0295, -0.0263,  0.0517,  0.0066, -0.0504, -0.0060,  0.0214,  0.0014]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0083,  0.0019, -0.0342, -0.0046,  0.0636, -0.0529, -0.0529,  0.0618,\n",
            "          0.0040,  0.0159, -0.0586,  0.0105,  0.0354, -0.0233,  0.0198, -0.0464,\n",
            "          0.0518,  0.0379,  0.0498, -0.0302,  0.0097, -0.0390,  0.0501, -0.0177,\n",
            "          0.0183, -0.0106,  0.0354,  0.0059, -0.0475, -0.0003,  0.0102, -0.0040,\n",
            "          0.0083,  0.0019, -0.0342, -0.0046,  0.0636, -0.0529, -0.0529,  0.0618,\n",
            "          0.0040,  0.0159, -0.0586,  0.0105,  0.0354, -0.0233,  0.0198, -0.0464,\n",
            "          0.0518,  0.0379,  0.0498, -0.0302,  0.0097, -0.0390,  0.0501, -0.0177,\n",
            "          0.0183, -0.0106,  0.0354,  0.0059, -0.0475, -0.0003,  0.0102, -0.0040]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038,\n",
            "         -0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038],\n",
            "        [-0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038,\n",
            "         -0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038,\n",
            "         -0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038],\n",
            "        [-0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038,\n",
            "         -0.1413, -0.0396, -0.0800,  0.0704, -0.0957, -0.0046,  0.0131, -0.0651,\n",
            "         -0.0277,  0.0790,  0.0268, -0.0660,  0.0477, -0.1557,  0.0235, -0.0404,\n",
            "         -0.0887,  0.0271, -0.0158,  0.1087, -0.0762,  0.0732,  0.0188, -0.0109,\n",
            "          0.0365,  0.0004,  0.0535,  0.0830,  0.0412, -0.0453,  0.0457,  0.1038]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0839, -0.0067, -0.0515,  0.0524, -0.0671,  0.0039,  0.0059, -0.0562,\n",
            "         -0.0177,  0.0677,  0.0147, -0.0479,  0.0411, -0.0898,  0.0115, -0.0182,\n",
            "         -0.0711,  0.0222, -0.0092,  0.0943, -0.0503,  0.0508, -0.0040,  0.0003,\n",
            "          0.0222, -0.0001,  0.0357,  0.0654,  0.0484, -0.0239,  0.0403,  0.0561,\n",
            "         -0.0839, -0.0067, -0.0515,  0.0524, -0.0671,  0.0039,  0.0059, -0.0562,\n",
            "         -0.0177,  0.0677,  0.0147, -0.0479,  0.0411, -0.0898,  0.0115, -0.0182,\n",
            "         -0.0711,  0.0222, -0.0092,  0.0943, -0.0503,  0.0508, -0.0040,  0.0003,\n",
            "          0.0222, -0.0001,  0.0357,  0.0654,  0.0484, -0.0239,  0.0403,  0.0561]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493,\n",
            "          0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493],\n",
            "        [ 0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493,\n",
            "          0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493,\n",
            "          0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493],\n",
            "        [ 0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493,\n",
            "          0.0146,  0.0196, -0.0185, -0.1490, -0.0786,  0.0446, -0.0848, -0.0084,\n",
            "          0.0575,  0.0643, -0.1323,  0.0679,  0.0814,  0.0035, -0.0009,  0.0659,\n",
            "          0.0417, -0.0205,  0.0120,  0.0117, -0.0667, -0.0863,  0.0550, -0.1709,\n",
            "         -0.0561,  0.0276, -0.0254, -0.0806, -0.1087,  0.0420, -0.0730, -0.1493]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0148,  0.0160, -0.0153, -0.1088, -0.0636,  0.0272, -0.0598, -0.0203,\n",
            "          0.0460,  0.0520, -0.0915,  0.0525,  0.0530, -0.0067, -0.0024,  0.0302,\n",
            "          0.0261, -0.0108,  0.0195,  0.0043, -0.0428, -0.0658,  0.0284, -0.1131,\n",
            "         -0.0347,  0.0272, -0.0235, -0.0448, -0.0764,  0.0247, -0.0579, -0.1015,\n",
            "          0.0148,  0.0160, -0.0153, -0.1088, -0.0636,  0.0272, -0.0598, -0.0203,\n",
            "          0.0460,  0.0520, -0.0915,  0.0525,  0.0530, -0.0067, -0.0024,  0.0302,\n",
            "          0.0261, -0.0108,  0.0195,  0.0043, -0.0428, -0.0658,  0.0284, -0.1131,\n",
            "         -0.0347,  0.0272, -0.0235, -0.0448, -0.0764,  0.0247, -0.0579, -0.1015]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921,\n",
            "          0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921],\n",
            "        [ 0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921,\n",
            "          0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921,\n",
            "          0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921],\n",
            "        [ 0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921,\n",
            "          0.0392,  0.0864,  0.1317, -0.0246,  0.1335, -0.0755, -0.0422,  0.0021,\n",
            "          0.1524, -0.0619,  0.0091, -0.0017,  0.0067,  0.0913, -0.0061, -0.0223,\n",
            "          0.0488,  0.0176, -0.0608,  0.0428, -0.0058,  0.0795,  0.0471,  0.0449,\n",
            "          0.0314,  0.0489,  0.0105, -0.0148, -0.0366, -0.0566, -0.1405, -0.0921]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0374,  0.0546,  0.0947, -0.0185,  0.1002, -0.0514, -0.0310,  0.0013,\n",
            "          0.1150, -0.0619,  0.0059,  0.0050,  0.0174,  0.0621, -0.0040, -0.0233,\n",
            "          0.0482,  0.0037, -0.0536,  0.0299, -0.0133,  0.0548,  0.0385,  0.0370,\n",
            "          0.0214,  0.0252,  0.0165,  0.0028, -0.0369, -0.0309, -0.0854, -0.0712,\n",
            "          0.0374,  0.0546,  0.0947, -0.0185,  0.1002, -0.0514, -0.0310,  0.0013,\n",
            "          0.1150, -0.0619,  0.0059,  0.0050,  0.0174,  0.0621, -0.0040, -0.0233,\n",
            "          0.0482,  0.0037, -0.0536,  0.0299, -0.0133,  0.0548,  0.0385,  0.0370,\n",
            "          0.0214,  0.0252,  0.0165,  0.0028, -0.0369, -0.0309, -0.0854, -0.0712]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149,\n",
            "          0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149],\n",
            "        [ 0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149,\n",
            "          0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[ 0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149,\n",
            "          0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149],\n",
            "        [ 0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149,\n",
            "          0.0048, -0.0721,  0.0079,  0.0127,  0.0059, -0.0220, -0.0540, -0.1012,\n",
            "         -0.0144, -0.0328,  0.0612,  0.0519,  0.0274,  0.1375,  0.0303, -0.0350,\n",
            "          0.0153, -0.0725,  0.0034, -0.0298, -0.0551, -0.0159,  0.0463, -0.0934,\n",
            "          0.0646, -0.0208,  0.0356,  0.0336, -0.0281, -0.0834,  0.0631,  0.0149]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0064, -0.0619, -0.0074,  0.0003,  0.0007, -0.0161, -0.0454, -0.0752,\n",
            "          0.0002, -0.0185,  0.0509,  0.0269,  0.0177,  0.0800,  0.0223, -0.0335,\n",
            "          0.0084, -0.0486,  0.0011, -0.0079, -0.0256, -0.0151,  0.0237, -0.0718,\n",
            "          0.0365, -0.0187,  0.0082,  0.0427, -0.0222, -0.0604,  0.0469,  0.0216,\n",
            "         -0.0064, -0.0619, -0.0074,  0.0003,  0.0007, -0.0161, -0.0454, -0.0752,\n",
            "          0.0002, -0.0185,  0.0509,  0.0269,  0.0177,  0.0800,  0.0223, -0.0335,\n",
            "          0.0084, -0.0486,  0.0011, -0.0079, -0.0256, -0.0151,  0.0237, -0.0718,\n",
            "          0.0365, -0.0187,  0.0082,  0.0427, -0.0222, -0.0604,  0.0469,  0.0216]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625,\n",
            "         -0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625],\n",
            "        [-0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625,\n",
            "         -0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625,\n",
            "         -0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625],\n",
            "        [-0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625,\n",
            "         -0.0870,  0.0152,  0.0226, -0.0972, -0.0150, -0.0045,  0.0468, -0.0418,\n",
            "          0.0552,  0.0509,  0.0726, -0.0888,  0.0724, -0.0915,  0.0648, -0.0580,\n",
            "         -0.0027, -0.0285,  0.0771, -0.0290,  0.1107,  0.0010, -0.0417,  0.0358,\n",
            "          0.0337, -0.0051,  0.0602, -0.0957,  0.0935, -0.1350,  0.0623,  0.0625]],\n",
            "       grad_fn=<CatBackward>)\n",
            "tensor([[-0.0761,  0.0179,  0.0195, -0.0694, -0.0030, -0.0192,  0.0391, -0.0310,\n",
            "          0.0351,  0.0293,  0.0445, -0.0631,  0.0412, -0.0812,  0.0440, -0.0324,\n",
            "         -0.0022, -0.0103,  0.0590, -0.0105,  0.0848, -0.0034, -0.0243,  0.0120,\n",
            "          0.0269,  0.0031,  0.0424, -0.0824,  0.0601, -0.0904,  0.0566,  0.0220,\n",
            "         -0.0761,  0.0179,  0.0195, -0.0694, -0.0030, -0.0192,  0.0391, -0.0310,\n",
            "          0.0351,  0.0293,  0.0445, -0.0631,  0.0412, -0.0812,  0.0440, -0.0324,\n",
            "         -0.0022, -0.0103,  0.0590, -0.0105,  0.0848, -0.0034, -0.0243,  0.0120,\n",
            "          0.0269,  0.0031,  0.0424, -0.0824,  0.0601, -0.0904,  0.0566,  0.0220]],\n",
            "       grad_fn=<CatBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvi0n_YKF0x"
      },
      "source": [
        "print(y)  # initial predictions without training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln1XgFXjKXL2"
      },
      "source": [
        "optimizer = optim.Adam(mansf.parameters())\r\n",
        "loss_fn = nn.BCELoss()\r\n",
        "\r\n",
        "for epoch in range(100):\r\n",
        "    mansf.train()\r\n",
        "    y = mansf(p, m, neighborhoods)\r\n",
        "    loss = loss_fn(y.view(-1), Y.view(-1))\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    print(y[0].item(), y[1].item(), y[2].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "laFsXLtlL6Ai",
        "outputId": "ba6f4d5f-e71d-4a96-ae8d-90e35ae24e16"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d9183e048de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrZFtsoENPHE"
      },
      "source": [
        "p_test = torch.tensor([[[1.3, 1.6, 1.0], [1.4, 1.5, 1.2]], [[0.83, 0.91, 0.67], [0.75, 0.89, 0.56]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWn4om-ENfys"
      },
      "source": [
        "m_test = [torch.zeros(2,1,64),torch.zeros(2,1,64)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUv2f2ofNizl"
      },
      "source": [
        "y_test = mansf(p_test, m_test, neighborhoods)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnvXt58hNone"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7WqGMFQOZA6"
      },
      "source": [
        "p_test2 = torch.tensor([[[0.83, 0.91, 0.67], [0.75, 0.89, 0.56]], [[1.3, 1.6, 1.0], [1.4, 1.5, 1.2]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gshnkeQJOfDl"
      },
      "source": [
        "m_test2 = [torch.zeros(2,1,64),torch.zeros(2,1,64)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieovkdZHOgWs"
      },
      "source": [
        "y_test2 = mansf(p_test2, m_test2, neighborhoods)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOzt8_FAOiCc"
      },
      "source": [
        "print(y_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxCeTPkshTiD"
      },
      "source": [
        "#Sandbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXK3JLoK4SgP"
      },
      "source": [
        "##Price Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrA5qKZwhTK7"
      },
      "source": [
        "T = 5  # number of days in lookback window\r\n",
        "batch_size = 4\r\n",
        "gru_p_hidden_size = 64\r\n",
        "\r\n",
        "p = torch.rand(batch_size, T, 3)  # p_i = [p_i^c, p_i^h, p_i^l], not bothering to normalize for shape tests\r\n",
        "\r\n",
        "print('p.shape', p.shape)\r\n",
        "\r\n",
        "h_p_0 = torch.randn(1, batch_size, gru_p_hidden_size)  # randomly initialized initial hidden state\r\n",
        "gru_p = GRU(3, gru_p_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "h_p, h_p_n = gru_p(p, h_p_0)\r\n",
        "\r\n",
        "print('h_p.shape', h_p.shape)\r\n",
        "print('h_p_n.shape', h_p_n.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXkpe2m1oE7p"
      },
      "source": [
        "attn_p_intermediate_size = 10\r\n",
        "\r\n",
        "attn_p = LinearAttention(gru_p_hidden_size, attn_p_intermediate_size, 1)\r\n",
        "\r\n",
        "q = attn_p(h_p)\r\n",
        "\r\n",
        "print('q.shape', q.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfVX_mwE4Upm"
      },
      "source": [
        "##SMI Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpbYUa13FP2T"
      },
      "source": [
        "K = [7, 9, 11, 13, 15]  # number of tweets for each day in lookback window\r\n",
        "T = 5  # number or days in lookback window\r\n",
        "batch_size = 4\r\n",
        "gru_m_hidden_size = 64\r\n",
        "use_embedding_size = 512\r\n",
        "\r\n",
        "r = torch.zeros(batch_size, 0, gru_m_hidden_size)\r\n",
        "\r\n",
        "gru_m = GRU(use_embedding_size, gru_m_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "for t in range(T):\r\n",
        "\r\n",
        "    m = torch.rand(batch_size, K[0], use_embedding_size)\r\n",
        "\r\n",
        "    print('m.shape', m.shape)\r\n",
        "\r\n",
        "    h_m_0 = torch.randn(1, batch_size, gru_m_hidden_size)  # randomly initialized initial hidden state\r\n",
        "\r\n",
        "    h_m, h_m_n = gru_m(m, h_m_0)\r\n",
        "\r\n",
        "    print('h_m.shape', h_m.shape)\r\n",
        "    print('h_m_n.shape', h_m_n.shape)\r\n",
        "\r\n",
        "    attn_m_intermediate_size = 10\r\n",
        "\r\n",
        "    attn_m = LinearAttention(gru_m_hidden_size, attn_m_intermediate_size, 1)\r\n",
        "\r\n",
        "    r_t = attn_m(h_m)\r\n",
        "\r\n",
        "    print('r_t.shape', r_t.shape)\r\n",
        "\r\n",
        "    r = torch.cat((r, r_t), 1)\r\n",
        "\r\n",
        "    print('r.shape', r.shape)\r\n",
        "\r\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enAqzfkmdfeQ"
      },
      "source": [
        "gru_s_hidden_size = 64\r\n",
        "\r\n",
        "print('r.shape', r.shape)\r\n",
        "\r\n",
        "h_s_0 = torch.randn(1, batch_size, gru_s_hidden_size)  # randomly initialized initial hidden state\r\n",
        "gru_s = GRU(gru_m_hidden_size, gru_s_hidden_size, batch_first=True)\r\n",
        "\r\n",
        "h_s, h_s_n = gru_s(r, h_s_0)\r\n",
        "\r\n",
        "print('h_s.shape', h_s_0.shape)\r\n",
        "print('h_s_n.shape', h_s_n.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXAAWKgffdf8"
      },
      "source": [
        "attn_s_intermediate_size = 10\r\n",
        "\r\n",
        "attn_s = LinearAttention(gru_s_hidden_size, attn_s_intermediate_size, 1)\r\n",
        "\r\n",
        "c = attn_s(h_s)\r\n",
        "\r\n",
        "print('c.shape', c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Jz8KgBl6e9"
      },
      "source": [
        "##Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzPwjITrmyf7"
      },
      "source": [
        "blend_size = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Zr5i8_l50p"
      },
      "source": [
        "blend = Blend(q.shape[2], c.shape[2], blend_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeSZ46RQm0MU"
      },
      "source": [
        "x = blend(q, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcwZyMyem98Q"
      },
      "source": [
        "print('x.shape', x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1odW9AqrnHsh"
      },
      "source": [
        "num_stocks = x.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyQFkoZRnPGI"
      },
      "source": [
        "x = x.view(x.shape[0], x.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrE9r47wnVTc"
      },
      "source": [
        "print('x.shape', x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wQptn1PhF4O"
      },
      "source": [
        "##GAT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYM_oYYiZ_MU"
      },
      "source": [
        "intermediate_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tqq-lLkfgyd"
      },
      "source": [
        "nhoods = [[0,1], [0,1,2], [1,2], [3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qG6e1Kcf_EV"
      },
      "source": [
        "shared_linear = SharedLinear(blend_size, intermediate_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrVwW5zQhJ3y"
      },
      "source": [
        "Wx = shared_linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BzfEWPBhkPr"
      },
      "source": [
        "print('Wx.shape', Wx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvWXAd_bkq3a"
      },
      "source": [
        "##MGAT 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pioV0X1TkrlQ"
      },
      "source": [
        "U = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PgSNyF_ozT_"
      },
      "source": [
        "elu = nn.ELU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Uu_ONMk_QD"
      },
      "source": [
        "sgat = SGAT(intermediate_size, 1)\r\n",
        "\r\n",
        "z = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "z = elu(z)\r\n",
        "\r\n",
        "for i in range(1, num_stocks):\r\n",
        "    z_i = sgat(Wx, nhoods, i)\r\n",
        "    z_i = elu(z_i)\r\n",
        "    z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "for u in range(1, U):\r\n",
        "    sgat = SGAT(intermediate_size, 1)\r\n",
        "\r\n",
        "    z_u = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "    z_u = elu(z_u)\r\n",
        "\r\n",
        "    for i in range(1, num_stocks):\r\n",
        "        z_u_i = sgat(Wx, nhoods, i)\r\n",
        "        z_u_i = elu(z_u_i)\r\n",
        "        z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "    \r\n",
        "    z = torch.cat((z, z_u), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVvTf8HSlr8H"
      },
      "source": [
        "print('z.shape', z.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPqJ4buPo8IK"
      },
      "source": [
        "##MGAT 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5pZ6tAou4N"
      },
      "source": [
        "U = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhQUWzqdpBPH"
      },
      "source": [
        "sigmoid = nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWhGU4dGpYJ6"
      },
      "source": [
        "new_intermediate_size = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOBKmXt2pRL0"
      },
      "source": [
        "shared_linear = SharedLinear(z.shape[1], new_intermediate_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbWJ366upbMn"
      },
      "source": [
        "Wx = shared_linear(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuGp_MB6piJt"
      },
      "source": [
        "print('Wx.shape', Wx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMM1wNxhpCe6"
      },
      "source": [
        "sgat = SGAT(new_intermediate_size, 1)\r\n",
        "\r\n",
        "z = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "z = sigmoid(z)\r\n",
        "\r\n",
        "for i in range(1, num_stocks):\r\n",
        "    z_i = sgat(Wx, nhoods, i)\r\n",
        "    z_i = sigmoid(z_i)\r\n",
        "    z = torch.cat((z, z_i), 0)\r\n",
        "\r\n",
        "for u in range(1, U):\r\n",
        "    sgat = SGAT(new_intermediate_size, 1)\r\n",
        "\r\n",
        "    z_u = sgat(Wx, nhoods, 0)\r\n",
        "\r\n",
        "    z_u = sigmoid(z_u)\r\n",
        "\r\n",
        "    for i in range(1, num_stocks):\r\n",
        "        z_u_i = sgat(Wx, nhoods, i)\r\n",
        "        z_u_i = sigmoid(z_u_i)\r\n",
        "        z_u = torch.cat((z_u, z_u_i), 0)\r\n",
        "    \r\n",
        "    z = torch.cat((z, z_u), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDpzJU-BpzTu"
      },
      "source": [
        "print('z.shape', z.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH8yQvp8p6CP"
      },
      "source": [
        "##Final Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhLolFHp_td"
      },
      "source": [
        "linear = nn.Linear(z.shape[1], 1, bias=True)\r\n",
        "sigmoid = nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNdZdAALqgMn"
      },
      "source": [
        "sigmoid(linear(z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIpPquknIZ23"
      },
      "source": [
        "print(sigmoid(linear(z)).shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}